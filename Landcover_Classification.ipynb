{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landcover Classification \n",
    "\n",
    "## Authored by: Blake Marshall, Sean Farmer, Jacob Sellers, & Isauro Ramos\n",
    "\n",
    "The Landcover Classification project aims to... <CONTINUE DESCRIPTION>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gdal\n",
    "%pip install rasterio\n",
    "%pip install raster2xyz\n",
    "%pip install matplotlib\n",
    "%pip install scikit-learn\n",
    "%pip install seaborn\n",
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from raster2xyz.raster2xyz import Raster2xyz\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I (Sam) downloaded the sample data to my own drive to access it. It will probably be a good idea to make it downloadable\n",
    "path_samples = 'Data/Images/'\n",
    "file_name = '1_ang20231028t101421_014_L2A_OE_main_27577724_RFL_ORT.tif'\n",
    "path_test_tiff = path_samples + file_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Rasterio into Dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = rasterio.open(path_test_tiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Bands\n",
    "print(dataset_1.count)\n",
    "# Image Resolution\n",
    "print(dataset_1.height, dataset_1.width)\n",
    "# CRS (Coordinate Reference System)\n",
    "print(dataset_1.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the GeoTIFF file\n",
    "with rasterio.open(path_test_tiff) as src:\n",
    "    # Read the data as a numpy array\n",
    "    data = src.read(1) # Read the first band\n",
    "\n",
    "    # Create a DataFrame with the pixel values\n",
    "    df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the first band of the tiff in relationship to the pixels. 10x10 size\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the GeoTIFF file\n",
    "with rasterio.open(path_test_tiff) as dataset:\n",
    "    # Read the data as a numpy array\n",
    "    data_3D = dataset.read()\n",
    "\n",
    "    # Print the data\n",
    "    print(data_3D.shape)\n",
    "\n",
    "    # Visualize the data\n",
    "    show(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(path_test_tiff) as dataset:\n",
    "    # Read the bands as numpy arrays\n",
    "    band_57 = dataset.read(57)  # Adjust with correct band number\n",
    "    band_35 = dataset.read(35)  # Adjust with correct band number\n",
    "    band_21 = dataset.read(21)  # Adjust with correct band number\n",
    "\n",
    "    # Stack the bands to form a 3-channel (RGB) image\n",
    "    rgb_image = np.stack([band_57, band_35, band_21], axis=-1)\n",
    "    # Normalize the values (optional, depending on the image data scale)\n",
    "    rgb_image = rgb_image / np.max(rgb_image)  # Normalize to [0, 1]\n",
    "\n",
    "    # Plot the image\n",
    "    plt.imshow(rgb_image)\n",
    "    plt.title(\"Composite Image with Bands 57, 35, 21\")\n",
    "    plt.axis('off')  # Turn off axis\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Functions using rasterio to make 1D arrays of the bands corrisponding to their pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiff_to_arr(filepath):\n",
    "  '''\n",
    "  Description:\n",
    "    This function takes a filepath to a .tiff file, opens it, and reads it as a\n",
    "    numpy arr. Then returns said array.\n",
    "  Input:\n",
    "    filepath  : The file path to the .tiff file, starting from /content/...\n",
    "  Output:\n",
    "    data_3D   : A 3 dimensional array of frequency bands for the pixels of an\n",
    "                image.\n",
    "  '''\n",
    "  with rasterio.open(filepath) as dataset:\n",
    "      # Read the data as a numpy array\n",
    "      data_3D = dataset.read()\n",
    "  return data_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_3D_to_1D(data_3D):\n",
    "  '''\n",
    "  Description:\n",
    "    This function takes a 3 dimensional array of frequence bands when each\n",
    "    individual frequence reading is a NxN 2D array. So this 3D array is BxNxN\n",
    "    where B is the number of frequence bands. This function will return a N*NxB\n",
    "    array. Where every individual frequence corresponding to a pixel is in the\n",
    "    returned 1D array for each of the N*N pixels.\n",
    "  Input:\n",
    "    data_3D         : Numpy Array with 3 dimensions of shape (num_band, num_row, num_col)\n",
    "  Output:\n",
    "    bands_per_pixel : Numpy Array of shape (num_row * numcol, num_band)\n",
    "  '''\n",
    "  temp_list_1D_arr = []\n",
    "\n",
    "  # Access the depth (third dimension) and create 1D arrays\n",
    "  for i in range(data_3D.shape[1]):                 # 10 for both data_3D.shape[1] & data_3D.shape[2] to make the 10x10\n",
    "    for j in range(data_3D.shape[2]):\n",
    "      data_1D = data_3D[:, i, j].flatten()          # EX. this will take the [0,0] for every bands then flatten that into a 1D array. For all the bands corresponding to pixel [0,0]\n",
    "      temp_list_1D_arr.append(data_1D)              # append to the temp list\n",
    "  bands_per_pixel = np.array(temp_list_1D_arr)      # convert the list to a numpy array... because I want to.\n",
    "  return bands_per_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames(directory_path):\n",
    "    '''\n",
    "     * Description:\n",
    "     *   gets the name of both files and directories at path_samples\n",
    "     *   sorted by the first numeric prefix in the filename\n",
    "     * Input(s):\n",
    "     *   directory_path: the path to the directory containing sample files\n",
    "     * Output(s):\n",
    "     *   Sorted Numpy Array of Filenames, array of strings\n",
    "    '''\n",
    "    filenames = []\n",
    "    for f in listdir(directory_path):\n",
    "        # Ignore hidden files and directories (like .DS_Store)\n",
    "        if f.startswith(\".\") or not isfile(join(directory_path, f)):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Try to parse the first part of the filename as an integer\n",
    "            int(f.split(\"_\")[0])\n",
    "            filenames.append(f)  # Only add to the list if parsing succeeds\n",
    "        except ValueError:\n",
    "            print(f\"Non-numeric prefix found in filename: {f}\")  # Print any problematic filename\n",
    "\n",
    "    # Sort the valid filenames and convert to a numpy array\n",
    "    return np.array(sorted(filenames, key=lambda x: int(x.split(\"_\")[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pandas_dataframe(dir_path, filename, col_labels):\n",
    "  #ds = convert_3D_to_1D(tiff_to_arr(join(dir_path, filename)))\n",
    "  ds = tiff_to_arr(join(dir_path, filename))\n",
    "  df = pd.DataFrame(ds, columns=col_labels)\n",
    "  df['File'] = filename\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data(sample_directory_path):\n",
    "  #Creates the frequency labels\n",
    "  columns_of_frequencies = []\n",
    "  for i in range(0,373,1):\n",
    "    columns_of_frequencies.append(\"frq\" + str(i))\n",
    "\n",
    "  # get an array of the sample file names\n",
    "  filenames = get_filenames(sample_directory_path)\n",
    "\n",
    "  ## This is where we would trim the filenames for the ones we want\n",
    "\n",
    "  #loop through and add to pandas dataframe\n",
    "  list_df = []\n",
    "  for i in range(0, len(filenames)):\n",
    "    list_df.append(make_pandas_dataframe(sample_directory_path, filenames[i], columns_of_frequencies))\n",
    "    #print(i)\n",
    "\n",
    "  return pd.concat(list_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_make_pandas_dataframe(dir_path, filename, col_labels):\n",
    "    ds = tiff_to_arr(join(dir_path, filename))  # shape is (373, 10, 10)\n",
    "\n",
    "    # Reshape to have each pixel position with 373 band values as a row\n",
    "    reshaped_ds = ds.reshape(ds.shape[0], -1).T  # Shape becomes (100, 373) or (121, 373) depending on the data\n",
    "    print(f\"reshaped_ds shape: {reshaped_ds.shape}\")  # Check shape of reshaped_ds\n",
    "\n",
    "    # Create the DataFrame with band columns\n",
    "    df = pd.DataFrame(reshaped_ds, columns=col_labels[:reshaped_ds.shape[1]])\n",
    "\n",
    "    # Dynamically generate X and Y coordinates based on the number of rows in reshaped_ds\n",
    "    num_rows = reshaped_ds.shape[0]\n",
    "    x_vals = np.tile(np.arange(10), num_rows // 10)\n",
    "    y_vals = np.repeat(np.arange(10), num_rows // 10)\n",
    "\n",
    "    # Adjust lengths in case of rounding issues\n",
    "    if len(x_vals) != num_rows:\n",
    "        x_vals = np.resize(x_vals, num_rows)\n",
    "    if len(y_vals) != num_rows:\n",
    "        y_vals = np.resize(y_vals, num_rows)\n",
    "\n",
    "    # Check if lengths match\n",
    "    print(f\"Length of X: {len(x_vals)}, Length of Y: {len(y_vals)}, Num Rows: {num_rows}\")\n",
    "    \n",
    "    df['X'] = x_vals  # X coordinates\n",
    "    df['Y'] = y_vals  # Y coordinates\n",
    "\n",
    "    # Add filename for tracking\n",
    "    df['File'] = filename\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_get_all_data(sample_directory_path):\n",
    "  #Creates the frequency labels\n",
    "  columns_of_frequencies = []\n",
    "  for i in range(0,373,1):\n",
    "    columns_of_frequencies.append(\"frq\" + str(i))\n",
    "\n",
    "  # get an array of the sample file names\n",
    "  filenames = get_filenames(sample_directory_path)\n",
    "\n",
    "  ## This is where we would trim the filenames for the ones we want\n",
    "\n",
    "  #loop through and add to pandas dataframe\n",
    "  list_df = []\n",
    "  for i in range(0, len(filenames)):\n",
    "    list_df.append(pca_make_pandas_dataframe(sample_directory_path, filenames[i], columns_of_frequencies))\n",
    "    #print(i)\n",
    "\n",
    "  return pd.concat(list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# large then needed data so that slows this down but still needs work\n",
    "df = pca_get_all_data(path_samples) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count file name rows? to see what images are larger?\n",
    "# filenames size is 3650\n",
    "df #why is there 415959 rows? aren't the sizes supposed to be 10x10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[0])\n",
    "print(df.iloc[99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Drop non-numeric columns like 'X', 'Y', and 'File'\n",
    "features = df.drop(columns=['X', 'Y', 'File'])\n",
    "\n",
    "# Standardize the data (if features have different scales)\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Convert the NumPy array to a pandas DataFrame and preserve the original index\n",
    "features_scaled_df = pd.DataFrame(features_scaled, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with any NaN values, while preserving the index\n",
    "features_scaled_dropped = features_scaled_df.dropna()\n",
    "\n",
    "# Ensure that there are no more NaN values\n",
    "print(features_scaled_dropped.isnull().sum())\n",
    "\n",
    "# Verify the row count of features_scaled_dropped and df\n",
    "print(f\"features_scaled_dropped rows: {len(features_scaled_dropped)}\")\n",
    "print(f\"Original df rows: {len(df)}\")\n",
    "\n",
    "# Initialize PCA and reduce to 2 principal components\n",
    "pca = PCA(n_components=2)  # Adjust the number of components if needed\n",
    "principal_components = pca.fit_transform(features_scaled_dropped)\n",
    "\n",
    "# Create a DataFrame for the PCA results\n",
    "pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n",
    "\n",
    "# Check the index length after dropping NaNs\n",
    "print(f\"pca_df rows: {len(pca_df)}\")\n",
    "\n",
    "# Reset the index of df if it has a custom index\n",
    "df_reset = df.reset_index(drop=True)\n",
    "\n",
    "# Align the rows of df with the rows that remain in features_scaled_dropped\n",
    "pca_df['X'] = df_reset.loc[features_scaled_dropped.index, 'X'].values\n",
    "pca_df['Y'] = df_reset.loc[features_scaled_dropped.index, 'Y'].values\n",
    "pca_df['File'] = df_reset.loc[features_scaled_dropped.index, 'File'].values\n",
    "\n",
    "# Show the first few rows of the PCA result\n",
    "print(pca_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the first two principal components\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(pca_df['PC1'], pca_df['PC2'], c=pca_df['X'] + pca_df['Y'], cmap='viridis')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('PCA: First Two Principal Components')\n",
    "plt.colorbar(label='Pixel Position (X + Y)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explained variance ratio\n",
    "print(f'Explained variance ratio for each component: {pca.explained_variance_ratio_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of components to explain 90% of the variance\n",
    "pca = PCA(n_components=0.90)  # Keep enough components to explain 90% variance\n",
    "principal_components = pca.fit_transform(features_scaled_dropped)\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "pca_full = PCA()\n",
    "principal_components_full = pca_full.fit_transform(features_scaled_dropped)\n",
    "explained_variance_ratio_full = pca_full.explained_variance_ratio_\n",
    "\n",
    "print(f\"Number of components to explain 90% variance: {pca.n_components_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_full = PCA()\n",
    "principal_components_full = pca_full.fit_transform(features_scaled_dropped)\n",
    "explained_variance_ratio_full = pca_full.explained_variance_ratio_\n",
    "pca_full.explained_variance_ratio_[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the explained variance ratio for all components\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(explained_variance_ratio_full) + 1), explained_variance_ratio_full, marker='o', linestyle='--')\n",
    "plt.title('Explained Variance per Principal Component')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.xticks(range(1, len(explained_variance_ratio_full) + 1))\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Determine the number of components to explain 90% of the variance\n",
    "pca = PCA(n_components=0.90)\n",
    "principal_components = pca.fit_transform(features_scaled_dropped)\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "print(f\"Number of components to explain 90% variance: {pca.n_components_}\")\n",
    "\n",
    "# Optional: Cumulative explained variance plot\n",
    "cumulative_variance = np.cumsum(explained_variance_ratio_full)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='--')\n",
    "plt.axhline(y=0.90, color='r', linestyle='--', label=\"90% Variance\")\n",
    "plt.title('Cumulative Explained Variance')\n",
    "plt.xlabel('Principal Componenst')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the component loadings (how much each feature contributes to each component)\n",
    "component_loadings = pca.components_\n",
    "\n",
    "# Convert it to a DataFrame for easier inspection\n",
    "loadings_df = pd.DataFrame(component_loadings, columns=features.columns)\n",
    "\n",
    "# For each component, get the top 6 features with the highest absolute loadings\n",
    "top_n = pca.n_components_\n",
    "top_features = {}\n",
    "\n",
    "for i in range(loadings_df.shape[0]):  # Loop through each component\n",
    "    # Sort the values by absolute magnitude and get the top 6\n",
    "    sorted_loadings = loadings_df.iloc[i].abs().sort_values(ascending=False).head(top_n)\n",
    "    top_features[f\"Component {i+1}\"] = sorted_loadings\n",
    "\n",
    "# Convert the result to a DataFrame for better presentation\n",
    "top_features_df = pd.DataFrame(top_features)\n",
    "\n",
    "# Print the top 6 features for each component\n",
    "print(top_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set to store the distinct frequencies used in the top features\n",
    "used_frequencies = set()\n",
    "\n",
    "# Loop through each component and add the top N frequencies to the set\n",
    "for i in range(loadings_df.shape[0]):  # Loop through each component\n",
    "    # Get the top features for the component by sorting by absolute magnitude\n",
    "    sorted_loadings = loadings_df.iloc[i].abs().sort_values(ascending=False).head(top_n)\n",
    "    # Add the indices (frequencies) of these top features to the set\n",
    "    used_frequencies.update(sorted_loadings.index)\n",
    "\n",
    "# Count the total number of unique frequencies used\n",
    "total_used_frequencies = len(used_frequencies)\n",
    "\n",
    "# Print the total number of unique frequencies\n",
    "print(f\"Total number of frequencies used across all components: {total_used_frequencies}\")\n",
    "\n",
    "# Print the names of the features (frequencies) used\n",
    "print(\"\\nFrequencies used across all components:\")\n",
    "for feature in used_frequencies:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Principal Components To Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the principal components to a DataFrame\n",
    "principal_components_df = pd.DataFrame(\n",
    "    principal_components, \n",
    "    columns=[f'PC{i+1}' for i in range(pca.n_components_)]\n",
    ")\n",
    "\n",
    "# Reset the index for consistency\n",
    "principal_components_df = principal_components_df.reset_index(drop=True)\n",
    "\n",
    "# Reset index in df to align with features_scaled_dropped\n",
    "df_reset = df.reset_index(drop=True)\n",
    "\n",
    "# Select 'X', 'Y', and 'File' columns from df\n",
    "xy_file_df = df_reset[['X', 'Y', 'File']].iloc[:len(principal_components_df)].reset_index(drop=True)\n",
    "\n",
    "# Concatenate the selected columns with the principal components\n",
    "data_with_pcs = pd.concat([xy_file_df, principal_components_df], axis=1)\n",
    "\n",
    "# Print the first 100 rows of the new dataset to verify\n",
    "print(data_with_pcs.head())\n",
    "#use the data_with_pcs to train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract the first 100 pixels, each with 3 components\n",
    "# Assuming data_with_pcs is a DataFrame with columns PC1, PC2, PC3 for each pixel\n",
    "first_100_pixels = data_with_pcs[['PC1', 'PC2', 'PC3']].iloc[:100].values  # First 100 pixels with 3 components each\n",
    "\n",
    "# Step 2: Reshape the data to 10x10x3 (image_dim x image_dim x 3 components per pixel)\n",
    "image_dim = 10  # 10x10 image\n",
    "reconstructed_image = first_100_pixels.reshape(image_dim, image_dim, 3)  # 3 components per pixel\n",
    "\n",
    "# Step 3: Combine the 3 components into a single grayscale image (for simplicity)\n",
    "combined_image = np.mean(reconstructed_image, axis=-1)  # Averaging the 3 components for grayscale\n",
    "\n",
    "# Step 4: Display the reconstructed image\n",
    "plt.imshow(combined_image)  # Display as grayscale\n",
    "plt.title('Reconstructed Image from PCA')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning With ResNet50 (Not Yet Functional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from tensorflow.keras.applications import ResNet50\n",
    "#from tensorflow.keras.models import Model\n",
    "#from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "#from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the ResNet50 model pre-trained on ImageNet without the top layer\n",
    "#base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Add custom layers for terrain classification\n",
    "#x = base_model.output\n",
    "#x = GlobalAveragePooling2D()(x)  # Global Average Pooling\n",
    "#x = Dense(1024, activation='relu')(x)  # Fully connected layer\n",
    "#predictions = Dense(5, activation='softmax')(x)  # Output layer (assuming 5 terrain classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create the final model\n",
    "#model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Freeze the layers of the base model (ResNet50) initially\n",
    "#for layer in base_model.layers:\n",
    "#    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Compile the model\n",
    "#model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Train the model (initial training)\n",
    "#model.fit(train_generator, epochs=5, steps_per_epoch=train_generator.samples // train_generator.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Fine-tune the model: Unfreeze the top layers of the base model\n",
    "#for layer in base_model.layers[-10:]:  # Unfreeze the last 10 layers of ResNet50\n",
    "#    layer.trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Recompile and retrain the model\n",
    "#model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#model.fit(train_generator, epochs=5, steps_per_epoch=train_generator.samples // train_generator.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Save the model\n",
    "#model.save('resnet_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "excel_file = 'Labels/CNN_Sample_Boxes_Subset_241018.xlsx'\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(excel_file, sheet_name=5)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Access specific columns\n",
    "image_numbers = df['Sample_num']\n",
    "labels = df['Class']\n",
    "\n",
    "# Access specific rows\n",
    "first_row = df.iloc[0]  # First row as a Series\n",
    "first_value = df.iloc[0, 0]  # First cell value\n",
    "\n",
    "# Iterate over rows\n",
    "#for index, row in df.iterrows():\n",
    "   # print(f\"Sample_num: {row['Sample_num']}, Label: {row['Class']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "def assign_images_to_samples(image_folder, labels_excel, output_folder, sheet_index=5):\n",
    "    \"\"\"\n",
    "    Assigns images to each Sample_num and Class pair from the DataFrame,\n",
    "    matching the filenames exactly to the format Sample_num + \"_\".\n",
    "\n",
    "    Args:\n",
    "    - image_folder (str): Path to the folder containing the images.\n",
    "    - labels_excel (str): Path to the Excel file containing Sample_num and Class labels.\n",
    "    - output_folder (str): Path to the output folder where organized data will be saved.\n",
    "    - sheet_index (int): Index of the sheet to read from the Excel file.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Read the specified sheet from the Excel file\n",
    "    df = pd.read_excel(labels_excel, sheet_name=sheet_index)\n",
    "\n",
    "    # Convert Sample_num to integers, then to strings\n",
    "    df['Sample_num'] = df['Sample_num'].apply(lambda x: str(int(x)) if not pd.isna(x) else None)\n",
    "\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Iterate through the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        sample_num = row['Sample_num']\n",
    "        label = row['Class']\n",
    "\n",
    "        if sample_num is None:\n",
    "            print(f\"Skipping row {index} with missing Sample_num\")\n",
    "            continue\n",
    "\n",
    "        # Find the matching image in the image folder\n",
    "        assigned_image = None\n",
    "        for image_file in os.listdir(image_folder):\n",
    "            # Match files that start with Sample_num followed by \"_\"\n",
    "            if image_file.startswith(f\"{sample_num}_\") and image_file.lower().endswith(('.tif', '.jpg', '.jpeg', '.png')):\n",
    "                assigned_image = image_file\n",
    "                break\n",
    "\n",
    "        # Check if an image was found\n",
    "        if assigned_image:\n",
    "            # Create a subdirectory for the label if it doesn't exist\n",
    "            label_folder = os.path.join(output_folder, str(label))\n",
    "            os.makedirs(label_folder, exist_ok=True)\n",
    "\n",
    "            # Copy the image to the appropriate label folder\n",
    "            source_path = os.path.join(image_folder, assigned_image)\n",
    "            destination_path = os.path.join(label_folder, assigned_image)\n",
    "            shutil.copy(source_path, destination_path)\n",
    "        else:\n",
    "            print(f\"No image found for Sample_num {sample_num}\")\n",
    "\n",
    "    print(f\"Images organized into {output_folder}.\")\n",
    "\n",
    "# Example usage\n",
    "#assign_images_to_samples(\n",
    "#    image_folder=\"/content/drive/MyDrive/Landcover-Classification_11-17/Images\",\n",
    "#    labels_excel=\"/content/drive/MyDrive/Landcover-Classification_11-17/CNN_Sample_Boxes_Subset_241018.xlsx\",\n",
    "#    output_folder=\"/content/drive/MyDrive/Landcover-Classification_11-17/Organized_Images\"\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Step 1: Prepare the input and labels\n",
    "# Assuming the data has a target class column. For simplicity, we'll create dummy labels.\n",
    "# Replace 'dummy_labels' with your actual labels if available.\n",
    "num_samples = len(data_with_pcs)\n",
    "#print(num_samples)\n",
    "dummy_labels = np.random.randint(0, 2, size=num_samples)  # Replace with actual labels\n",
    "\n",
    "# Extract the first three principal components as features\n",
    "X = data_with_pcs[['PC1', 'PC2', 'PC3']].values\n",
    "y = LabelEncoder().fit_transform(dummy_labels)  # Encode labels if they are categorical\n",
    "\n",
    "#print(f\"Original shape of X: {X.shape}\")\n",
    "#print(f\"Total elements in X: {X.size}\")\n",
    "\n",
    "\n",
    "# Determine number of valid samples\n",
    "num_samples = X.shape[0] // 100  # Each sample needs 10x10=100 rows\n",
    "\n",
    "# Truncate and reshape\n",
    "X = X[:num_samples * 100]        # Truncate extra rows\n",
    "X = X.reshape(num_samples, 10, 10, 3)  # Reshape to (num_samples, 10, 10, 3)\n",
    "\n",
    "# Adjust labels\n",
    "y = y[:num_samples]\n",
    "\n",
    "#print(f\"New shape of X: {X.shape}\")  # Should be (num_samples, 10, 10, 3)\n",
    "#print(f\"New length of y: {len(y)}\")\n",
    "\n",
    "# Proceed with train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y[:num_samples], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Step 2: Define a simple CNN\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(10, 10, 3)),\n",
    "    \n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 3: Train the model ###This method might take longer to run but provides a high accuracy\n",
    "kf = KFold(n_splits=5)\n",
    "for train_idx, val_idx in kf.split(X):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "# Step 4: Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "# Step 5: Use the model to predict\n",
    "predictions = model.predict(X_test)\n",
    "print(f\"Predictions: {np.argmax(predictions, axis=1)[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers, regularizers\n",
    "\n",
    "def hyperspectral_cnn(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Create a 2D CNN model for hyperspectral image classifacation with reduced overfitting.\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        # First Convolutional Block\n",
    "        layers.Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=input_shape, kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(16, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Second Convolutional Block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "         # Third Convolutional Block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Fourth Convolutional Block\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        # Dense Layer\n",
    "        layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        # Output Layer\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers, regularizers\n",
    "\n",
    "def new_hyperspectral_cnn(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Create a 2D CNN model optimized for small spatial dimensions (e.g., 10x10).\n",
    "    Handles hyperspectral image classification with reduced spatial pooling.\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        # First Convolutional Block\n",
    "        layers.Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=input_shape, kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(16, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2), padding='same'),  # Spatial dims: 10x10 -> 5x5\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Second Convolutional Block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2), padding='same'),  # Spatial dims: 5x5 -> 3x3\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Third Convolutional Block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        # Replace MaxPooling with GlobalAveragePooling to handle small dimensions\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.4),\n",
    "        \n",
    "        # Dense Layer\n",
    "        layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        # Output Layer\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tifffile\n",
    "%pip install imagecodecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tifffile import imread\n",
    "\n",
    "def get_images_and_labels_tifffile(image_folder, labels_file):\n",
    "    \"\"\"\n",
    "    Reads TIFF images and their corresponding labels from a folder and CSV file.\n",
    "    Skips images without corresponding labels in the CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    - image_folder: str, path to the folder containing the images.\n",
    "    - labels_file: str, path to the CSV file containing the labels.\n",
    "\n",
    "    Returns:\n",
    "    - X: List of image data as NumPy arrays.\n",
    "    - y: List of corresponding labels.\n",
    "    \"\"\"\n",
    "    # Read the labels CSV\n",
    "    labels_df = pd.read_csv(labels_file)\n",
    "\n",
    "    # Create a dictionary mapping Sample_num to Class\n",
    "    labels_dict = dict(zip(labels_df['Sample_num'].astype(str), labels_df['Class']))\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Get all TIFF image files\n",
    "    image_files = [f for f in os.listdir(image_folder) if f.endswith('.tif')]\n",
    "\n",
    "    for image_file in image_files:\n",
    "        # Extract the sample number from the filename\n",
    "        sample_num = image_file.split('_')[0]\n",
    "\n",
    "        # Skip images without labels\n",
    "        if sample_num not in labels_dict:\n",
    "            print(f\"No label found for image: {image_file}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "\n",
    "        try:\n",
    "            # Read the TIFF image using tifffile\n",
    "            image = imread(image_path)\n",
    "\n",
    "            # Normalize image values to [0, 1]\n",
    "            image = image.astype(np.float32) / 255.0\n",
    "\n",
    "            # Append the image and its label to the lists\n",
    "            X.append(image)\n",
    "            y.append(labels_dict[sample_num])\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {image_file}: {e}\")\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_and_labels_rasterio(image_folder, labels_file):\n",
    "    \"\"\"\n",
    "    Reads TIFF images using rasterio and their corresponding labels from a folder and CSV file.\n",
    "    Skips images without corresponding labels in the CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    - image_folder: str, path to the folder containing the images.\n",
    "    - labels_file: str, path to the CSV file containing the labels.\n",
    "\n",
    "    Returns:\n",
    "    - X: List of image data as NumPy arrays.\n",
    "    - y: List of corresponding labels.\n",
    "    \"\"\"\n",
    "    # Read the labels CSV\n",
    "    labels_df = pd.read_csv(labels_file)\n",
    "\n",
    "    # Create a dictionary mapping Sample_num to Class\n",
    "    labels_dict = dict(zip(labels_df['Sample_num'].astype(str), labels_df['Class']))\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Get all TIFF image files\n",
    "    image_files = [f for f in os.listdir(image_folder) if f.endswith('.tif')]\n",
    "\n",
    "    for image_file in image_files:\n",
    "        # Extract the sample number from the filename\n",
    "        sample_num = image_file.split('_')[0]\n",
    "\n",
    "        # Skip images without labels\n",
    "        if sample_num not in labels_dict:\n",
    "            print(f\"No label found for image: {image_file}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "\n",
    "        try:\n",
    "            # Read the TIFF image using rasterio\n",
    "            with rasterio.open(image_path) as src:\n",
    "                image = src.read()  # Read the image as a NumPy array (bands x rows x cols)\n",
    "\n",
    "            # Normalize image values to [0, 1]\n",
    "            image = image.astype(np.float32) / np.iinfo(src.dtypes[0]).max  # Normalize by the max possible value\n",
    "\n",
    "            # Append the image and its label to the lists\n",
    "            X.append(image)\n",
    "            y.append(labels_dict[sample_num])\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {image_file}: {e}\")\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_labels_and_save(csv_file_path, labels_to_remove):\n",
    "    \"\"\"\n",
    "    Processes the class labels in a CSV file:\n",
    "    - Converts all class labels to lowercase for consistency.\n",
    "    - Removes rows with specific labels and rows with NaN values.\n",
    "    - Saves a new CSV file in the same directory as the original file.\n",
    "\n",
    "    Parameters:\n",
    "    - csv_file_path: str, path to the CSV file.\n",
    "    - labels_to_remove: list, class labels to remove (not case-sensitive).\n",
    "\n",
    "    Returns:\n",
    "    - processed_df: pandas DataFrame with updated labels.\n",
    "    - new_file_path: str, path to the saved new CSV file.\n",
    "    \"\"\"\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Ensure the 'Class' column exists\n",
    "    if 'Class' not in df.columns:\n",
    "        raise ValueError(\"The CSV file must have a 'Class' column.\")\n",
    "\n",
    "    # Convert all class labels to lowercase\n",
    "    df['Class'] = df['Class'].str.lower()\n",
    "\n",
    "    # Remove rows with NaN values in the 'Class' column\n",
    "    df = df.dropna(subset=['Class'])\n",
    "\n",
    "    # Remove rows with labels to remove (case-insensitive)\n",
    "    labels_to_remove_lower = [label.lower() for label in labels_to_remove]\n",
    "    df = df[~df['Class'].isin(labels_to_remove_lower)]\n",
    "\n",
    "    # Save the processed DataFrame to a new CSV file in the same directory\n",
    "    base_dir = os.path.dirname(csv_file_path)\n",
    "    new_file_name = \"Processed_\" + os.path.basename(csv_file_path)\n",
    "    new_file_path = os.path.join(base_dir, new_file_name)\n",
    "    df.to_csv(new_file_path, index=False)\n",
    "\n",
    "    return df, new_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_images(X, y):\n",
    "    \"\"\"\n",
    "    Augments images stored as NumPy arrays and updates labels accordingly.\n",
    "\n",
    "    Parameters:\n",
    "    - X: List of original images as NumPy arrays.\n",
    "    - y: List of original labels.\n",
    "\n",
    "    Returns:\n",
    "    - X_augmented: List of original and augmented images as NumPy arrays.\n",
    "    - y_augmented: List of labels corresponding to X_augmented.\n",
    "    \"\"\"\n",
    "    X_augmented = X.copy()\n",
    "    y_augmented = y.copy()\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        image = X[i]\n",
    "        label = y[i]\n",
    "\n",
    "        # Flip vertically\n",
    "        flipped_vert = np.flipud(image)\n",
    "        X_augmented.append(flipped_vert)\n",
    "        y_augmented.append(label)\n",
    "\n",
    "        # Flip horizontally\n",
    "        flipped_horiz = np.fliplr(image)\n",
    "        X_augmented.append(flipped_horiz)\n",
    "        y_augmented.append(label)\n",
    "\n",
    "        # Rotate 90 degrees clockwise\n",
    "        rotated = np.rot90(image, k=-1)  \n",
    "        X_augmented.append(rotated)\n",
    "        y_augmented.append(label)\n",
    "        \n",
    "        rotated_counterclockwise = np.rot90(image, k=1)  \n",
    "        X_augmented.append(rotated_counterclockwise)\n",
    "        y_augmented.append(label)\n",
    "\n",
    "    return X_augmented, y_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "\n",
    "\n",
    "def prepare_data_for_training(X, y, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Prepares data for training by resizing and normalizing images and splitting into train/test sets.\n",
    "\n",
    "    Parameters:\n",
    "    - X: List of images as NumPy arrays.\n",
    "    - y: List of labels.\n",
    "    - test_size: Fraction of the dataset to reserve for testing.\n",
    "    - random_state: Seed for random number generator.\n",
    "\n",
    "    Returns:\n",
    "    - X_train: Training images as NumPy arrays.\n",
    "    - X_test: Testing images as NumPy arrays.\n",
    "    - y_train: Training labels.\n",
    "    - y_test: Testing labels.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # Define target image size\n",
    "    target_size = (10,10)\n",
    "\n",
    "    # Initialize lists to hold resized image arrays\n",
    "    X_resized = []\n",
    "\n",
    "    for img in X:\n",
    "        # Resize image using OpenCV\n",
    "        resized_img = cv2.resize(img, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "        X_resized.append(resized_img)\n",
    "\n",
    "    # Normalize pixel values to [0, 1]\n",
    "    X_resized = np.array(X_resized).astype(np.float32) / 255.0\n",
    "    y_array = np.array(y)\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_resized, y_array,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        stratify=y_array\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import zoom\n",
    "\n",
    "def clean_data(X, y, target_shape=(10, 10)):\n",
    "    \"\"\"\n",
    "    Cleans and preprocesses the data:\n",
    "    - Removes invalid samples (nan or inf values in X).\n",
    "    - Resizes images to the target shape.\n",
    "\n",
    "    Parameters:\n",
    "    - X: list of image data (e.g., NumPy arrays of varying shapes).\n",
    "    - y: list of corresponding labels.\n",
    "    - target_shape: tuple, desired (height, width) for resizing images.\n",
    "\n",
    "    Returns:\n",
    "    - X_cleaned: numpy.ndarray, cleaned and resized input data.\n",
    "    - y_cleaned: numpy.ndarray, cleaned labels.\n",
    "    \"\"\"\n",
    "    X_cleaned = []\n",
    "    y_cleaned = []\n",
    "\n",
    "    for i, img in enumerate(X):\n",
    "        # Check for valid images (no nan or inf values)\n",
    "        if img is not None and not np.isnan(img).any() and not np.isinf(img).any():\n",
    "            try:\n",
    "                # Resize image to target shape while preserving channels\n",
    "                current_shape = img.shape\n",
    "                if current_shape[:2] != target_shape:\n",
    "                    zoom_factors = (target_shape[0] / current_shape[0],\n",
    "                                    target_shape[1] / current_shape[1],\n",
    "                                    1)  # Keep channels unchanged\n",
    "                    img = zoom(img, zoom_factors, order=1)  # Bilinear interpolation\n",
    "\n",
    "                # Append the resized and valid image\n",
    "                X_cleaned.append(img)\n",
    "                y_cleaned.append(y[i])\n",
    "            except AttributeError:\n",
    "                print(f\"Image {i} is not a valid NumPy array. Skipping.\")\n",
    "        else:\n",
    "            print(f\"Image {i} contains invalid values (nan or inf). Skipping.\")\n",
    "\n",
    "    return np.array(X_cleaned), np.array(y_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageFolderPath = 'Data/Images'\n",
    "labelsFilePath = 'Data/ConsolidatedLabels.csv'\n",
    "\n",
    "df, new_file_path = process_labels_and_save(labelsFilePath, ['nan', 'Tie', '#N/A'])\n",
    "\n",
    "# rasterio_X, rasterio_y = get_images_and_labels_rasterio(imageFolderPath, new_file_path)\n",
    "tifffile_X, tifffile_y = get_images_and_labels_tifffile(imageFolderPath, new_file_path)\n",
    "\n",
    "# cleaned_tifffile_X, cleaned_tifffile_y = clean_data(tifffile_X, tifffile_y)\n",
    "\n",
    "# new_rasterio_X, new_rasterio_y = augment_images(rasterio_X, rasterio_y)\n",
    "new_tifffile_X, new_tifffile_y = augment_images(tifffile_X, tifffile_y)\n",
    "\n",
    "# print(f\"Original data: {len(rasterio_X)} images, {len(rasterio_y)} labels\")\n",
    "# print(f\"Augmented data: {len(new_rasterio_X)} images, {len(new_rasterio_y)} labels\")\n",
    "\n",
    "print(f\"Original data: {len(tifffile_X)} images, {len(tifffile_y)} labels\")\n",
    "\n",
    "print(f\"Augmented data: {len(new_tifffile_X)} images, {len(new_tifffile_y)} labels\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cleaned_tifffile_X, cleaned_tifffile_y = clean_data(new_tifffile_X, new_tifffile_y, (10, 10))\n",
    "print(f\"Cleaned data: {len(cleaned_tifffile_X)} images, {len(cleaned_tifffile_y)} labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = prepare_data_for_training(cleaned_tifffile_X, cleaned_tifffile_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from label strings to integers\n",
    "unique_labels = sorted(set(y_train))\n",
    "label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "print(f\"Label to integer mapping: {label_to_int}\")\n",
    "print(f\"Unique labels: {unique_labels}\")\n",
    "print(\"unique labels:\",set(unique_labels))\n",
    "print(\"unique labels:\",len(set(unique_labels)))\n",
    "\n",
    "# Convert y_train and y_test to integers\n",
    "y_train = [label_to_int[label] for label in y_train]\n",
    "y_test = [label_to_int[label] for label in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = hyperspectral_cnn(input_shape=(dataset_1.height, dataset_1.width, dataset_1.count), num_classes=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print shapes to check compatibility\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"Model input shape:\", cnn_model.input_shape)\n",
    "\n",
    "# Print data types to ensure consistency\n",
    "print(\"X_train dtype:\", X_train.dtype)\n",
    "print(\"X_test dtype:\", X_test.dtype)\n",
    "print(\"y_train dtype:\", type(y_train))\n",
    "print(\"y_test dtype:\", type(y_test))\n",
    "\n",
    "# Convert y_train and y_test to NumPy arrays with integer type\n",
    "y_train = np.array(y_train, dtype=np.int32)\n",
    "y_test = np.array(y_test, dtype=np.int32)\n",
    "\n",
    "# Verify the conversion\n",
    "print(\"y_train dtype:\", y_train.dtype)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test dtype:\", y_test.dtype)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# Convert X_train and X_test to NumPy arrays with float32 type\n",
    "X_train = np.array(X_train, dtype=np.float32)\n",
    "X_test = np.array(X_test, dtype=np.float32)\n",
    "\n",
    "# Verify the conversion\n",
    "print(\"X_train dtype:\", X_train.dtype)\n",
    "print(\"X_test dtype:\", X_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique labels and their range\n",
    "\n",
    "# print(\"X_train range:\", X_train.min(), X_train.max())\n",
    "\n",
    "# print(\"Unique labels in y_train:\", np.unique(y_train))\n",
    "# print(\"Unique labels in y_test:\", np.unique(y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3, min_lr=1e-6)\n",
    "\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, cnn_model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Plots the training and validation accuracy and loss from the history object.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    y_pred = cnn_model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "    # Display the confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=range(12))\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot accuracy vs val_accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss vs val_loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Get predicted labels\n",
    "y_pred = cnn_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=range(12))\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the highest validation accuracy and corresponding epoch\n",
    "best_val_accuracy = max(history.history['val_accuracy'])\n",
    "best_epoch = history.history['val_accuracy'].index(best_val_accuracy) + 1\n",
    "\n",
    "print(f\"Highest Validation Accuracy: {best_val_accuracy:.4f}\")\n",
    "print(f\"Epoch with Highest Validation Accuracy: {best_epoch}\")\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_pred = cnn_model.predict(X_test)\n",
    "\n",
    "# Convert to percentages\n",
    "y_pred_percentages = y_pred * 100\n",
    "\n",
    "for i in range(best_epoch):\n",
    "    print(f\"Sample {i}:\")\n",
    "    for cls, prob in enumerate(y_pred_percentages[i]):\n",
    "        print(f\"  Class {cls}: {prob:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def plot_class_distribution(y, class_names, title=\"Class Distribution\"):\n",
    "    \"\"\"\n",
    "    Plots a histogram showing the distribution of samples across classes.\n",
    "\n",
    "    Parameters:\n",
    "    - y: array-like, labels for the dataset (as strings or integers).\n",
    "    - class_names: list, names of the classes corresponding to the labels.\n",
    "    - title: str, title for the plot.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Count occurrences of each class\n",
    "    class_counts = Counter(y)\n",
    "    \n",
    "    # Ensure the order of bars matches class_names\n",
    "    counts = [class_counts.get(cls, 0) for cls in class_names]\n",
    "\n",
    "    # Create a bar plot\n",
    "    plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
    "    plt.bar(class_names, counts)\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "    plt.grid(axis='y')\n",
    "    plt.tight_layout()  # Adjust layout to prevent label cutoff\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def get_class_counts(y, class_names=None):\n",
    "    \"\"\"\n",
    "    Returns the count of samples for each class in the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - y: array-like, labels for the dataset (as strings or integers).\n",
    "    - class_names: list, optional, names of the classes corresponding to the labels.\n",
    "\n",
    "    Returns:\n",
    "    - class_counts: dict, mapping of class names (or labels) to their counts.\n",
    "    \"\"\"\n",
    "    # Count occurrences of each class\n",
    "    class_counts = Counter(y)\n",
    "    \n",
    "    # Map counts to class names if provided\n",
    "    if class_names is not None:\n",
    "        class_counts = {class_names[int(label)]: count for label, count in class_counts.items()}\n",
    "\n",
    "    return class_counts\n",
    "\n",
    "# Assuming y_train and y_test are NumPy arrays or lists of numeric or string labels\n",
    "combined_labels = np.concatenate((y_train, y_test))  # Combine datasets if needed\n",
    "combined_labels = [str(label) for label in combined_labels]  # Convert to strings if necessary\n",
    "\n",
    "# Define class names (if numeric labels are used)\n",
    "class_names = sorted(set(combined_labels))  # Replace with your actual class names if needed\n",
    "\n",
    "# Get class counts\n",
    "class_counts = get_class_counts(combined_labels)\n",
    "\n",
    "# Print class counts\n",
    "for class_name, count in class_counts.items():\n",
    "    print(f\"{class_name}: {count}\")\n",
    "\n",
    "# Plot the class distribution\n",
    "plot_class_distribution(combined_labels, class_names, title=\"Class Distribution for Entire Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Add class weights to help with data imbalance\"\"\"\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "def calculate_class_weights(class_counts):\n",
    "    \"\"\"\n",
    "    Calculates class weights to handle class imbalance.\n",
    "\n",
    "    Parameters:\n",
    "    - class_counts: dict, mapping of class names or indices to their counts.\n",
    "\n",
    "    Returns:\n",
    "    - class_weights: dict, mapping of class indices to weights.\n",
    "    \"\"\"\n",
    "    total_samples = sum(class_counts.values())\n",
    "    num_classes = len(class_counts)\n",
    "\n",
    "    # Ensure class indices are numeric\n",
    "    class_weights = {\n",
    "        idx: total_samples / (num_classes * count)\n",
    "        for idx, count in enumerate(class_counts.values())\n",
    "    }\n",
    "\n",
    "    return class_weights\n",
    "\n",
    "# Example usage\n",
    "# Combine training and testing labels\n",
    "combined_labels = np.concatenate((y_train, y_test))  # Ensure y_train and y_test are NumPy arrays\n",
    "combined_labels = [str(label) for label in combined_labels]  # Convert labels to strings if needed\n",
    "\n",
    "# Dynamically get class counts\n",
    "class_counts = get_class_counts(combined_labels)\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = calculate_class_weights(class_counts)\n",
    "\n",
    "# Print class weights for verification\n",
    "print(\"Class Weights:\")\n",
    "for idx, (class_name, weight) in enumerate(zip(class_counts.keys(), class_weights.values())):\n",
    "    print(f\"Class {idx} ('{class_name}') weight: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights\n",
    "class_weights = calculate_class_weights(class_counts)\n",
    "\n",
    "cnn_model_2 = hyperspectral_cnn(input_shape=(10, 10, 373), num_classes=12)\n",
    "\n",
    "# Train the model with class weights\n",
    "history_2 = cnn_model_2.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stopping, lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy vs val_accuracy\n",
    "plt.plot(history_2.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_2.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss vs val_loss\n",
    "plt.plot(history_2.history['loss'], label='Training Loss')\n",
    "plt.plot(history_2.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get predicted labels\n",
    "# y_pred_2 = cnn_model_2.predict(X_test)\n",
    "# y_pred_classes_2 = np.argmax(y_pred_2, axis=1)\n",
    "\n",
    "# # Compute confusion matrix\n",
    "# conf_matrix_2 = confusion_matrix(y_test, y_pred_classes_2)\n",
    "\n",
    "# # Display the confusion matrix\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix_2, display_labels=range(12)) \n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# Get predicted labels\n",
    "y_pred_2 = cnn_model_2.predict(X_test)\n",
    "y_pred_classes_2 = np.argmax(y_pred_2, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix_2 = confusion_matrix(y_test, y_pred_classes_2)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix_2, display_labels=range(12))\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the highest validation accuracy and corresponding epoch\n",
    "best_val_accuracy_2 = max(history_2.history['val_accuracy'])\n",
    "best_epoch_2 = history_2.history['val_accuracy'].index(best_val_accuracy_2) + 1\n",
    "\n",
    "print(f\"Highest Validation Accuracy: {best_val_accuracy_2:.4f}\")\n",
    "print(f\"Epoch with Highest Validation Accuracy: {best_epoch_2}\")\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_pred_2 = cnn_model_2.predict(X_test)\n",
    "\n",
    "# Convert to percentages\n",
    "y_pred_percentages_2 = y_pred_2 * 100\n",
    "\n",
    "for i in range(best_epoch_2):\n",
    "    print(f\"Sample {i}:\")\n",
    "    for cls, prob in enumerate(y_pred_percentages_2[i]):\n",
    "        print(f\"  Class {cls}: {prob:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "# def modify_pretrained_model(new_input_shape, base_model_name='ResNet50', num_classes=10):\n",
    "#     \"\"\"\n",
    "#     Modifies a pre-trained model to accept a new input shape and updates the first layer accordingly.\n",
    "\n",
    "#     Args:\n",
    "#         new_input_shape (tuple): The new input shape, e.g., (10, 10, 373).\n",
    "#         base_model_name (str): Name of the pre-trained model to use. Default is 'ResNet50'.\n",
    "#         num_classes (int): Number of classes for the final classification layer.\n",
    "\n",
    "#     Returns:\n",
    "#         tf.keras.Model: The modified model ready for training.\n",
    "#     \"\"\"\n",
    "#     # Validate input shape for compatibility with pre-trained models\n",
    "#     if len(new_input_shape) != 3:\n",
    "#         raise ValueError(\"Input shape must be a tuple of (height, width, channels).\")\n",
    "\n",
    "#     # Load the pre-trained model\n",
    "#     if base_model_name == 'ResNet50':\n",
    "#         base_model = tf.keras.applications.ResNet50(\n",
    "#             include_top=False,  # Exclude top layers\n",
    "#             weights='imagenet',  # Use ImageNet pre-trained weights\n",
    "#             input_shape=(None, None, 3)  # Keep original input channels for weight loading\n",
    "#         )\n",
    "#     else:\n",
    "#         raise ValueError(f\"Unsupported base model: {base_model_name}\")\n",
    "    \n",
    "#     # Create a new input layer\n",
    "#     new_input = Input(shape=new_input_shape)\n",
    "\n",
    "#     # Project 373 input channels to 3 using a 1x1 convolution\n",
    "#     x = Conv2D(3, (1, 1), activation='linear', name='channel_projection')(new_input)\n",
    "\n",
    "#     # Connect the rest of the pre-trained model\n",
    "#     x = base_model(x)\n",
    "\n",
    "#     # Add custom classification layers\n",
    "#     x = Flatten()(x)\n",
    "#     x = Dense(256, activation='relu')(x)\n",
    "#     output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "#     # Create the new model\n",
    "#     model = Model(inputs=new_input, outputs=output)\n",
    "\n",
    "#     # Compile the model\n",
    "#     model.compile(optimizer='adam', \n",
    "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), \n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "#     return model\n",
    "\n",
    "# # Example usage\n",
    "# new_input_shape = (10, 10, 373)\n",
    "# num_classes = 12\n",
    "# new_model = modify_pretrained_model(new_input_shape, num_classes=num_classes)\n",
    "# # new_model.summary()\n",
    "\n",
    "# new_history = new_model.fit(\n",
    "#     X_train, \n",
    "#     y_train,\n",
    "#     validation_data=(X_test, y_test),\n",
    "#     epochs=50,\n",
    "#     batch_size=32,\n",
    "#     class_weight=class_weights,\n",
    "#     callbacks=[early_stopping, lr_scheduler]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Data To HybridSN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This may be problematic. HybridSN does NOT provide the pre-trained model. Instead we'd have to train it ourselves, which is providing difficult due to compatibility issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/gokriznastic/HybridSN.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Data To Custom Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
