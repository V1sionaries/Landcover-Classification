{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKo-QeTVBxMR"
   },
   "source": [
    "# 2D Landcover Classification\n",
    "\n",
    "### About The Project\n",
    "\n",
    "This project was completed as a senior capstone project by Blake Marshall, Sean Farmer, Jacob Sellers, & Isauro Ramos at Sonoma State University in fall 2024.\n",
    "\n",
    "### A Larger Initiative: BioSCape\n",
    "\n",
    "This project is part of the larger **BioSCape** initiative, a collaboration aimed at understanding biodiversity in the Greater Cape Floristic Region.\n",
    "\n",
    "The **Biodiversity Survey of the Cape** is a NASA-SANSA Biodiversity research project focused on the Greater Cape Floristic Region of South Africa.\n",
    "\n",
    "- This initiative utilizes hyperspectral images captured by the AVIRIS-NG remote sensor to analyze and classify land cover types. These hyperspectral images, containing 432 bands, provide detailed spectral data that enable precise classification across diverse ecological categories.\n",
    "\n",
    "Learn more about [BioSCape](https://www.bioscape.io).\n",
    "\n",
    "### Land Cover Classification Categories\n",
    "\n",
    "- **Wetlands**\n",
    "- **Planted Forest**\n",
    "- **Permanent Crops** (e.g., vineyard)\n",
    "- **Unconsolidated Barren**\n",
    "- **Natural Grassland**\n",
    "- **Consolidated Barren** (e.g., rocks, salt pans)\n",
    "- **Built-up Areas**\n",
    "- **Mixed or Not Classified**\n",
    "- **Natural Wooded Land**\n",
    "- **Waterbodies**\n",
    "- **Annual Crops** (e.g., wheat)\n",
    "- **Shrubs**\n",
    "\n",
    "### Objectives\n",
    "\n",
    "1. **Hyperspectral Land Cover Mapping**  \n",
    "   Leveraged hyperspectral imaging from the remote sensor AVIRIS-NG to classify the terrain into the categories listed above.\n",
    "\n",
    "2. **2D Classification Approach**  \n",
    "   Explored a two-dimensional (2D) methodology for land cover classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPd3F-tSBxMW"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zc1AzGtcBxMW"
   },
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O6cFBEsCB9Ga",
    "outputId": "0aa88aaa-7b4c-418e-83f6-948421b5531a"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JOJnrkH3BxMX",
    "outputId": "ea471bd0-d019-4841-a092-2c52a097d7e8"
   },
   "outputs": [],
   "source": [
    "%pip install gdal\n",
    "%pip install rasterio\n",
    "%pip install raster2xyz\n",
    "%pip install matplotlib\n",
    "%pip install scikit-learn\n",
    "%pip install seaborn\n",
    "%pip install tensorflow\n",
    "%pip install tabulate\n",
    "%pip install scikit-image\n",
    "%pip install openpyxl\n",
    "\n",
    "%pip install tifffile\n",
    "%pip install imagecodecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vwKevfOBxMY"
   },
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "itHIPo3uBxMZ"
   },
   "outputs": [],
   "source": [
    "# File and directory handling\n",
    "import os\n",
    "import shutil\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Data handling and processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Raster and image processing\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from raster2xyz.raster2xyz import Raster2xyz\n",
    "from skimage.transform import resize\n",
    "from tifffile import imread\n",
    "from scipy.ndimage import zoom\n",
    "import cv2\n",
    "\n",
    "# Machine learning and data preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay, accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3N5WRiQBxMZ"
   },
   "source": [
    "## Handling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dSb8W_dBxMa"
   },
   "source": [
    "### Example Paths To Data & Label Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01tcnsXnBxMa"
   },
   "outputs": [],
   "source": [
    "\n",
    "path_samples = 'Data/Images/'\n",
    "file_name = '1_ang20231028t101421_014_L2A_OE_main_27577724_RFL_ORT.tif'\n",
    "path_test_tiff = path_samples + file_name\n",
    "'''\n",
    "#dont delete sean uses for google colab\n",
    "\n",
    "path_samples = '/content/drive/MyDrive/Landcover-Classification_11-17/Images'\n",
    "file_name = '1_ang20231028t101421_014_L2A_OE_main_27577724_RFL_ORT.tif'\n",
    "path_test_tiff = '/content/drive/MyDrive/Landcover-Classification_11-17/Images/1_ang20231028t101421_014_L2A_OE_main_27577724_RFL_ORT.tif'\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRuA12rDBxMb"
   },
   "source": [
    "### Peek To See Shape Of Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q6Dwg_lnBxMb",
    "outputId": "a0c76c8e-09c2-4640-a655-6ec10cfab2e1"
   },
   "outputs": [],
   "source": [
    "dataset_1 = rasterio.open(path_test_tiff)\n",
    "\n",
    "# Number of Bands\n",
    "print(dataset_1.count)\n",
    "# Image Resolution\n",
    "print(dataset_1.height, dataset_1.width)\n",
    "# CRS (Coordinate Reference System)\n",
    "print(dataset_1.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xPnIYJzBxMb"
   },
   "source": [
    "#### From this, we can see that the image has a resolution of 10X10 and consists of 373 bands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9NyADgByBxMb"
   },
   "source": [
    "## Visualizing An Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "id": "GP-7LvCuBxMb",
    "outputId": "d698b287-edbe-42ba-90da-952ecd256e0c"
   },
   "outputs": [],
   "source": [
    "# Open the GeoTIFF file\n",
    "with rasterio.open(path_test_tiff) as dataset:\n",
    "    # Read the data as a numpy array\n",
    "    data_3D = dataset.read()\n",
    "\n",
    "    # Print the data\n",
    "    print(data_3D.shape)\n",
    "\n",
    "    # Visualize the data\n",
    "    show(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjJdYRIFBxMc"
   },
   "source": [
    "#### This Image Contains All 373 Bands And Its Not Very Informative. Let's Try Something More Faimilar - Red, Green, & Blue (RGB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "k2-KYxgYBxMc",
    "outputId": "c8efc823-c404-46a8-a30a-01fb42815b7c"
   },
   "outputs": [],
   "source": [
    "with rasterio.open(path_test_tiff) as dataset:\n",
    "    # Read the bands as numpy arrays\n",
    "    band_57 = dataset.read(57)  # Adjust with correct band number\n",
    "    band_35 = dataset.read(35)  # Adjust with correct band number\n",
    "    band_21 = dataset.read(21)  # Adjust with correct band number\n",
    "\n",
    "    # Stack the bands to form a 3-channel (RGB) image\n",
    "    rgb_image = np.stack([band_57, band_35, band_21], axis=-1)\n",
    "    # Normalize the values (optional, depending on the image data scale)\n",
    "    rgb_image = rgb_image / np.max(rgb_image)  # Normalize to [0, 1]\n",
    "\n",
    "    # Plot the image\n",
    "    plt.imshow(rgb_image)\n",
    "    plt.title(\"Composite Image with Bands 57, 35, 21\")\n",
    "    plt.axis('off')  # Turn off axis\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ATGln6KBxMc"
   },
   "source": [
    "#### Now that we have an understanding of the data, we can begin work on the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5F2sOkYDBxMc"
   },
   "source": [
    "## Implement Funcitions To Unpack Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3wL5sFptBxMc"
   },
   "outputs": [],
   "source": [
    "def tiff_to_arr(filepath):\n",
    "  '''\n",
    "  Description:\n",
    "    This function takes a filepath to a .tiff file, opens it, and reads it as a\n",
    "    numpy arr. Then returns said array.\n",
    "  Input:\n",
    "    filepath  : The file path to the .tiff file, starting from /content/...\n",
    "  Output:\n",
    "    data_3D   : A 3 dimensional array of frequency bands for the pixels of an\n",
    "                image.\n",
    "  '''\n",
    "  with rasterio.open(filepath) as dataset:\n",
    "      # Read the data as a numpy array\n",
    "      data_3D = dataset.read()\n",
    "  return data_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EbLeOHzKBxMd"
   },
   "outputs": [],
   "source": [
    "def get_filenames(directory_path):\n",
    "    '''\n",
    "     * Description:\n",
    "     *   gets the name of both files and directories at path_samples\n",
    "     *   sorted by the first numeric prefix in the filename\n",
    "     * Input(s):\n",
    "     *   directory_path: the path to the directory containing sample files\n",
    "     * Output(s):\n",
    "     *   Sorted Numpy Array of Filenames, array of strings\n",
    "    '''\n",
    "    filenames = []\n",
    "    for f in listdir(directory_path):\n",
    "        # Ignore hidden files and directories (like .DS_Store)\n",
    "        if f.startswith(\".\") or not isfile(join(directory_path, f)):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Try to parse the first part of the filename as an integer\n",
    "            int(f.split(\"_\")[0])\n",
    "            filenames.append(f)  # Only add to the list if parsing succeeds\n",
    "        except ValueError:\n",
    "            print(f\"Non-numeric prefix found in filename: {f}\")  # Print any problematic filename\n",
    "\n",
    "    # Sort the valid filenames and convert to a numpy array\n",
    "    return np.array(sorted(filenames, key=lambda x: int(x.split(\"_\")[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3QywXHsWBxMd"
   },
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZwCpvhrBxMd"
   },
   "source": [
    "#### Given that we have 373 bands per image, this data can be hard to work with. To remedy this, we can use Principal Component Analysis (PCA). With PCA, Only the bands, or frequencies, with the most significant variance will been kept - the rest discarded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uTHGt5hBxMd"
   },
   "source": [
    "##### **Note:** From this point forward, the terms \"band\" and \"frequency\" will be used interchangeably as they represent the same thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "veFRFwr1BxMd"
   },
   "source": [
    "## Setup Functions For DataFrame Generation, Data Manipulation, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HaUIjo_RBxMd"
   },
   "outputs": [],
   "source": [
    "def pca_make_pandas_dataframe(dir_path, filename, col_labels):\n",
    "    ds = tiff_to_arr(join(dir_path, filename))  # shape is (373, 10, 10)\n",
    "\n",
    "    # Reshape to have each pixel position with 373 band values as a row\n",
    "    reshaped_ds = ds.reshape(ds.shape[0], -1).T  # Shape becomes (100, 373) or (121, 373) depending on the data\n",
    "    print(f\"reshaped_ds shape: {reshaped_ds.shape}\")  # Check shape of reshaped_ds\n",
    "\n",
    "    # Create the DataFrame with band columns\n",
    "    df = pd.DataFrame(reshaped_ds, columns=col_labels[:reshaped_ds.shape[1]])\n",
    "\n",
    "    # Dynamically generate X and Y coordinates based on the number of rows in reshaped_ds\n",
    "    num_rows = reshaped_ds.shape[0]\n",
    "    x_vals = np.tile(np.arange(10), num_rows // 10)\n",
    "    y_vals = np.repeat(np.arange(10), num_rows // 10)\n",
    "\n",
    "    # Adjust lengths in case of rounding issues\n",
    "    if len(x_vals) != num_rows:\n",
    "        x_vals = np.resize(x_vals, num_rows)\n",
    "    if len(y_vals) != num_rows:\n",
    "        y_vals = np.resize(y_vals, num_rows)\n",
    "\n",
    "    # Check if lengths match\n",
    "    print(f\"Length of X: {len(x_vals)}, Length of Y: {len(y_vals)}, Num Rows: {num_rows}\")\n",
    "\n",
    "    df['X'] = x_vals  # X coordinates\n",
    "    df['Y'] = y_vals  # Y coordinates\n",
    "\n",
    "    # Add filename for tracking\n",
    "    df['File'] = filename\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "APR66JuYBxMe"
   },
   "outputs": [],
   "source": [
    "def pca_get_all_data(sample_directory_path):\n",
    "  #Creates the frequency labels\n",
    "  columns_of_frequencies = []\n",
    "  for i in range(0,373,1):\n",
    "    columns_of_frequencies.append(\"frq\" + str(i))\n",
    "\n",
    "  # get an array of the sample file names\n",
    "  filenames = get_filenames(sample_directory_path)\n",
    "\n",
    "  ## This is where we would trim the filenames for the ones we want\n",
    "\n",
    "  #loop through and add to pandas dataframe\n",
    "  list_df = []\n",
    "  for i in range(0, len(filenames)):\n",
    "    list_df.append(pca_make_pandas_dataframe(sample_directory_path, filenames[i], columns_of_frequencies))\n",
    "    #print(i)\n",
    "\n",
    "  return pd.concat(list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XDp-_pZ2BxMe",
    "outputId": "41b6a064-266c-466c-dca2-dec638b45b2b"
   },
   "outputs": [],
   "source": [
    "df = pca_get_all_data(path_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ScLkvU-pBxMe"
   },
   "source": [
    "### Visualizing the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "fwfh-V6DBxMe",
    "outputId": "c7361d33-b833-4012-c84f-4007d96daa06"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JnaGQrnBxMf"
   },
   "source": [
    "##### Again, as we can see from the above dataframe, prior to PCA being performed, each pixel has 373 frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OqVJ0ZX2BxMf"
   },
   "source": [
    "### Reshape and Manipulate Data For PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0V7yhIudBxMf"
   },
   "source": [
    "##### The dataframe is not currently compatible with PCA. Let's remove nonumeric columns, remove NaNs, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OkWWowjsBxMf",
    "outputId": "a749cc1c-df51-4f25-beb2-d776807770bb"
   },
   "outputs": [],
   "source": [
    "# Drop non-numeric columns like 'X', 'Y', and 'File'\n",
    "features = df.drop(columns=['X', 'Y', 'File'])\n",
    "\n",
    "# Standardize the data (if features have different scales)\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Convert the NumPy array to a pandas DataFrame and preserve the original index\n",
    "features_scaled_df = pd.DataFrame(features_scaled, index=df.index)\n",
    "\n",
    "# Replace NaN values with 0 instead of dropping rows\n",
    "features_scaled_filled = features_scaled_df.fillna(0)\n",
    "\n",
    "# Verify the row count of features_scaled_filled and df\n",
    "print(f\"features_scaled_filled rows: {len(features_scaled_filled)}\")\n",
    "print(f\"Original df rows: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "byI_DbmWBxMf",
    "outputId": "01785019-781c-40a0-e448-ca86ca14eb38"
   },
   "outputs": [],
   "source": [
    "# Initialize PCA and reduce to 2 principal components\n",
    "pca = PCA(n_components=2)  # Adjust the number of components if needed\n",
    "principal_components = pca.fit_transform(features_scaled_filled)\n",
    "\n",
    "# Create a DataFrame for the PCA results\n",
    "pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n",
    "\n",
    "# Check the index length after dropping NaNs\n",
    "print(f\"pca_df rows: {len(pca_df)}\")\n",
    "\n",
    "# Reset the index of df if it has a custom index\n",
    "df_reset = df.reset_index(drop=True)\n",
    "\n",
    "# Align the rows of df with the rows that remain in features_scaled_dropped\n",
    "pca_df['X'] = df_reset.loc[features_scaled_filled.index, 'X'].values\n",
    "pca_df['Y'] = df_reset.loc[features_scaled_filled.index, 'Y'].values\n",
    "pca_df['File'] = df_reset.loc[features_scaled_filled.index, 'File'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Vr_6LRsBxMg",
    "outputId": "604b875f-8c99-49a7-f535-b4ee87846090"
   },
   "outputs": [],
   "source": [
    "# Show the first few rows of the PCA result\n",
    "print(pca_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "id": "tB3r8EQrBxMg",
    "outputId": "de1cee74-1fd5-40ec-e83b-0d54dbcbe65a"
   },
   "outputs": [],
   "source": [
    "# Visualize the first two principal components\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(pca_df['PC1'], pca_df['PC2'], c=pca_df['X'] + pca_df['Y'], cmap='viridis')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('PCA: First Two Principal Components')\n",
    "plt.colorbar(label='Pixel Position (X + Y)')\n",
    "plt.show()\n",
    "\n",
    "# Explained variance ratio\n",
    "print(f'Explained variance ratio for each component: {pca.explained_variance_ratio_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmzbYgMyBxMg"
   },
   "source": [
    "#### Here is an example of the result to PCA with two components. We can see that the first two components contain nearly 90% of the variance! We'd like a little more - let's keep trying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s7b1alKyBxMg"
   },
   "source": [
    "### Plotting PCA Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCS6aMSYBxMg"
   },
   "source": [
    "##### Let's plot a graph that will show us the necessary number of components for a specific amount of variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "id": "5rY4piFIBxMk",
    "outputId": "6ee5dabc-c804-41dc-8938-a3cac411a989"
   },
   "outputs": [],
   "source": [
    "# Assuming features_scaled_dropped is your pre-processed data\n",
    "pca_full = PCA()\n",
    "principal_components_full = pca_full.fit_transform(features_scaled_filled)\n",
    "explained_variance_ratio_full = pca_full.explained_variance_ratio_\n",
    "\n",
    "# Calculate cumulative explained variance\n",
    "cumulative_variance = np.cumsum(explained_variance_ratio_full)\n",
    "\n",
    "# Create a 1x2 subplot (1 row, 2 columns)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))  # Adjust the figsize as needed\n",
    "\n",
    "# Plot the explained variance ratio for all components\n",
    "axes[0].plot(range(1, len(explained_variance_ratio_full) + 1), explained_variance_ratio_full, marker='o', linestyle='--')\n",
    "axes[0].set_title('Explained Variance per Principal Component')\n",
    "axes[0].set_xlabel('Principal Component')\n",
    "axes[0].set_ylabel('Explained Variance Ratio')\n",
    "axes[0].set_xticks(range(1, len(explained_variance_ratio_full) + 1))\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Plot the cumulative explained variance\n",
    "axes[1].plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='--')\n",
    "axes[1].axhline(y=0.90, color='r', linestyle='--', label=\"90% Variance\")\n",
    "axes[1].set_title('Cumulative Explained Variance')\n",
    "axes[1].set_xlabel('Principal Components')\n",
    "axes[1].set_ylabel('Cumulative Explained Variance')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6EdW60uBxMl"
   },
   "source": [
    "##### It looks like we'll need to use three principal components in order to achieve 90%+ variance. Let's try this agian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Os-RpMo9BxMl",
    "outputId": "85210ff8-d319-4067-c1d5-b024b78439f0"
   },
   "outputs": [],
   "source": [
    "# Determine the number of components to explain 90% of the variance\n",
    "pca = PCA(n_components=0.90)  # Keep enough components to explain 90% variance\n",
    "principal_components = pca.fit_transform(features_scaled_filled)\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "print(f\"Number of components to explain 90% variance: {pca.n_components_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mnLmcne3BxMl",
    "outputId": "fa14b338-78a6-4d19-8ab4-13391c37cc78"
   },
   "outputs": [],
   "source": [
    "# Access the component loadings (how much each feature contributes to each component)\n",
    "component_loadings = pca.components_\n",
    "\n",
    "# Convert it to a DataFrame for easier inspection\n",
    "loadings_df = pd.DataFrame(component_loadings, columns=features.columns)\n",
    "\n",
    "# For each component, get the top 6 features with the highest absolute loadings\n",
    "top_n = pca.n_components_\n",
    "top_features = {}\n",
    "\n",
    "for i in range(loadings_df.shape[0]):  # Loop through each component\n",
    "    # Sort the values by absolute magnitude and get the top 6\n",
    "    sorted_loadings = loadings_df.iloc[i].abs().sort_values(ascending=False).head(top_n)\n",
    "    top_features[f\"Component {i+1}\"] = sorted_loadings\n",
    "\n",
    "# Convert the result to a DataFrame for better presentation\n",
    "top_features_df = pd.DataFrame(top_features)\n",
    "\n",
    "# Print the top 6 features for each component\n",
    "print(top_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cCnzaAzYBxMl",
    "outputId": "ff7715fc-b848-422c-c56d-74c5fbb223ac"
   },
   "outputs": [],
   "source": [
    "# Create a set to store the distinct frequencies used in the top features\n",
    "used_frequencies = set()\n",
    "\n",
    "# Loop through each component and add the top N frequencies to the set\n",
    "for i in range(loadings_df.shape[0]):  # Loop through each component\n",
    "    # Get the top features for the component by sorting by absolute magnitude\n",
    "    sorted_loadings = loadings_df.iloc[i].abs().sort_values(ascending=False).head(top_n)\n",
    "    # Add the indices (frequencies) of these top features to the set\n",
    "    used_frequencies.update(sorted_loadings.index)\n",
    "\n",
    "# Count the total number of unique frequencies used\n",
    "total_used_frequencies = len(used_frequencies)\n",
    "\n",
    "# Print the total number of unique frequencies\n",
    "print(f\"Total number of frequencies used across all components: {total_used_frequencies}\")\n",
    "\n",
    "# Print the names of the features (frequencies) used\n",
    "print(\"\\nFrequencies used across all components:\")\n",
    "for feature in used_frequencies:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpFOE19wBxMm"
   },
   "source": [
    "### Add Principal Components To Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QElA4R0GBxMm"
   },
   "source": [
    "##### Let's create a new dataframe that uses the three princiapl components, rather the 373 bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iSXv9d7KBxMm"
   },
   "outputs": [],
   "source": [
    "def add_principal_components(pca, principal_components, numComponents):\n",
    "    # Convert the principal components to a DataFrame\n",
    "    principal_components_df = pd.DataFrame(\n",
    "        principal_components,\n",
    "        columns=[f'PC{i+1}' for i in range(numComponents)]\n",
    "    )\n",
    "\n",
    "    # Reset the index for consistency\n",
    "    principal_components_df = principal_components_df.reset_index(drop=True)\n",
    "\n",
    "    # Reset index in df to align with features_scaled_dropped\n",
    "    df_reset = df.reset_index(drop=True)\n",
    "\n",
    "    # Select 'X', 'Y', and 'File' columns from df\n",
    "    xy_file_df = df_reset[['X', 'Y', 'File']].iloc[:len(principal_components_df)].reset_index(drop=True)\n",
    "\n",
    "    # Concatenate the selected columns with the principal components\n",
    "    return pd.concat([xy_file_df, principal_components_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvJLKiDwBxMm"
   },
   "source": [
    "##### Let's visualize the dataframe. We should see that each pixel contains 3 principal components and no additional frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v8TpfnxJBxMm",
    "outputId": "94c57f74-ed07-4bd7-83cd-9518ca244ecb"
   },
   "outputs": [],
   "source": [
    "data_with_pcs = add_principal_components(pca, principal_components, 3)\n",
    "# Print the first 100 rows of the new dataset to verify\n",
    "print(data_with_pcs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZ8tAuBXBxMn"
   },
   "source": [
    "### Visualizing an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AdK86BFBxMn"
   },
   "source": [
    "##### Re-assemble the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQDeA4WpBxMn"
   },
   "outputs": [],
   "source": [
    "# Step 1: Extract the first 100 pixels, each with 3 components\n",
    "# Assuming data_with_pcs is a DataFrame with columns PC1, PC2, PC3 for each pixel\n",
    "first_100_pixels = data_with_pcs[['PC1', 'PC2', 'PC3']].iloc[:100].values  # First 100 pixels with 3 components each\n",
    "\n",
    "# Step 2: Reshape the data to 10x10x3 (image_dim x image_dim x 3 components per pixel)\n",
    "image_dim = 10  # 10x10 image\n",
    "reconstructed_image = first_100_pixels.reshape(image_dim, image_dim, 3)  # 3 components per pixel\n",
    "\n",
    "# Step 3: Combine the 3 components into a single grayscale image (for simplicity)\n",
    "combined_image = np.mean(reconstructed_image, axis=-1)  # Averaging the 3 components for grayscale\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9RKb9lJBxMn"
   },
   "source": [
    "#### Now, let's view the first image in the dataset after PCA. We will compare it to the same image prior to PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "id": "9yY7ZWCBBxMn",
    "outputId": "6d892000-2a07-4baf-b7b1-ea7ac7f0d7c4"
   },
   "outputs": [],
   "source": [
    "# Create a figure for the plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))  # 1 row, 2 columns, adjust figure size\n",
    "\n",
    "# Subplot 1: Reconstructed Image from PCA\n",
    "axes[0].imshow(combined_image, aspect='equal')  # Maintain aspect ratio\n",
    "axes[0].set_title('Reconstructed Image from PCA')\n",
    "axes[0].axis('off')  # Remove axes for clean display\n",
    "\n",
    "# Subplot 2: Rasterio Visualization\n",
    "with rasterio.open(path_test_tiff) as dataset:\n",
    "    data_3D = dataset.read()  # Read the data as a numpy array\n",
    "    print(data_3D.shape)  # Print the shape of the 3D array\n",
    "\n",
    "    # Visualize the data using Rasterio\n",
    "    show(dataset, ax=axes[1], title='Original Image')\n",
    "\n",
    "# Adjust layout for clarity\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTlmImqoBxMo"
   },
   "source": [
    "#### Success! From this, we can see that there are new identifiable features! Let's try another for good measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWTTx3xkBxMo"
   },
   "source": [
    "#### Using Components 2, 3, & 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U8fxmouMBxMo"
   },
   "outputs": [],
   "source": [
    "# Extract components 2, 3, and 4 (indexing starts at 0, so these are columns 1, 2, and 3)\n",
    "selected_components = principal_components_full[:, 1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j3VZ8gLkBxMo",
    "outputId": "5fd8961e-5694-4615-8e11-bbf1f63a6cf7"
   },
   "outputs": [],
   "source": [
    "data_with_pcs2 = add_principal_components(pca_full, selected_components, 3)\n",
    "# Print the first 100 rows of the new dataset to verify\n",
    "print(data_with_pcs2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CnP6-WkiBxMo"
   },
   "source": [
    "##### **Note:** While the principal components are labeled PC1, PC2, PC3, these correspond to principal components 2, 3, & 4. Keeping them labeled this way allows for greater re-usability with our code.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RXiqSsYBxMp"
   },
   "source": [
    "##### Re-assemble the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eG1s1xXdBxMp"
   },
   "outputs": [],
   "source": [
    "# Step 1: Extract the first 100 pixels, each with 3 components\n",
    "# Assuming data_with_pcs is a DataFrame with columns PC1, PC2, PC3 for each pixel\n",
    "first_100_pixels = data_with_pcs2[['PC1', 'PC2', 'PC3']].iloc[:100].values  # First 100 pixels with 3 components each\n",
    "\n",
    "# Step 2: Reshape the data to 10x10x3 (image_dim x image_dim x 3 components per pixel)\n",
    "reconstructed_image2 = first_100_pixels.reshape(image_dim, image_dim, 3)  # 3 components per pixel\n",
    "\n",
    "# Step 3: Combine the 3 components into a single grayscale image (for simplicity)\n",
    "combined_image2 = np.mean(reconstructed_image2, axis=-1)  # Averaging the 3 components for grayscale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UnIlvw8dBxMp"
   },
   "source": [
    "### Let's visualize all three versions of the first image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "id": "o38Pp1TpBxMp",
    "outputId": "ae823b54-6b0b-4312-c26f-35e41718cd6c"
   },
   "outputs": [],
   "source": [
    "# Create a figure with 3 subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))  # 1 row, 3 columns, adjust figure size\n",
    "\n",
    "# Subplot 1: Reconstructed Image from PCA (Components 1, 2, 3)\n",
    "axes[0].imshow(combined_image, aspect='equal')  # Maintain aspect ratio\n",
    "axes[0].set_title('Reconstructed Image from PCA (Components 1, 2, 3)')\n",
    "axes[0].axis('off')  # Remove axes for clean display\n",
    "\n",
    "# Subplot 2: Reconstructed Image from PCA (Components 2, 3, 4)\n",
    "axes[1].imshow(combined_image2, aspect='equal')  # Maintain aspect ratio\n",
    "axes[1].set_title('Reconstructed Image from PCA (Components 2, 3, 4)')\n",
    "axes[1].axis('off')  # Remove axes for clean display\n",
    "\n",
    "# Subplot 3: Rasterio Visualization\n",
    "with rasterio.open(path_test_tiff) as dataset:\n",
    "    data_3D = dataset.read()  # Read the data as a numpy array\n",
    "    print(data_3D.shape)  # Print the shape of the 3D array\n",
    "\n",
    "    # Visualize the data using Rasterio\n",
    "    show(dataset, ax=axes[2], title='Original Image')\n",
    "\n",
    "# Adjust layout for clarity\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4L1xvNz9BxMp"
   },
   "source": [
    "##### Another success! We can see that using principal components 1, 2, & 3 produced different results from that of princiapl components 2, 3, & 4. Which one will yield better results? It's time to train some conputer vision models, let's find out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKLj_9W1BxMq"
   },
   "source": [
    "## Setup For Computer Vision Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Skf712pfBxMq"
   },
   "source": [
    "### Process Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M9b4d5WKBxMq",
    "outputId": "d6e8f9bb-6945-4e2e-d056-9413a4d9f813"
   },
   "outputs": [],
   "source": [
    "# Load the Excel file\n",
    "excel_file = 'Labels/CNN_Sample_Boxes_Subset_241018.xlsx'\n",
    "#excel_file = '/content/drive/MyDrive/Landcover-Classification_11-17/CNN_Sample_Boxes_Subset_241018.xlsx'\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(excel_file, sheet_name=5)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Access specific columns\n",
    "image_numbers = df['Sample_num']\n",
    "labels = df['Class']\n",
    "\n",
    "# Access specific rows\n",
    "first_row = df.iloc[0]  # First row as a Series\n",
    "first_value = df.iloc[0, 0]  # First cell value\n",
    "\n",
    "# Iterate over rows\n",
    "#for index, row in df.iterrows():\n",
    "   # print(f\"Sample_num: {row['Sample_num']}, Label: {row['Class']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MgfDiAQEBxMq",
    "outputId": "79cc6341-51f0-40b9-d329-a1733d39692a"
   },
   "outputs": [],
   "source": [
    "def assign_images_to_samples(image_folder, labels_excel, output_folder, sheet_index=5):\n",
    "    \"\"\"\n",
    "    Assigns images to each Sample_num and Class pair from the DataFrame,\n",
    "    matching the filenames exactly to the format Sample_num + \"_\".\n",
    "\n",
    "    Args:\n",
    "    - image_folder (str): Path to the folder containing the images.\n",
    "    - labels_excel (str): Path to the Excel file containing Sample_num and Class labels.\n",
    "    - output_folder (str): Path to the output folder where organized data will be saved.\n",
    "    - sheet_index (int): Index of the sheet to read from the Excel file.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Read the specified sheet from the Excel file\n",
    "    df = pd.read_excel(labels_excel, sheet_name=sheet_index)\n",
    "\n",
    "    # Convert Sample_num to integers, then to strings\n",
    "    df['Sample_num'] = df['Sample_num'].apply(lambda x: str(int(x)) if not pd.isna(x) else None)\n",
    "\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Iterate through the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        sample_num = row['Sample_num']\n",
    "        label = row['Class']\n",
    "\n",
    "        if sample_num is None:\n",
    "            print(f\"Skipping row {index} with missing Sample_num\")\n",
    "            continue\n",
    "\n",
    "        # Find the matching image in the image folder\n",
    "        assigned_image = None\n",
    "        for image_file in os.listdir(image_folder):\n",
    "            # Match files that start with Sample_num followed by \"_\"\n",
    "            if image_file.startswith(f\"{sample_num}_\") and image_file.lower().endswith(('.tif', '.jpg', '.jpeg', '.png')):\n",
    "                assigned_image = image_file\n",
    "                break\n",
    "\n",
    "        # Check if an image was found\n",
    "        if assigned_image:\n",
    "            # Create a subdirectory for the label if it doesn't exist\n",
    "            label_folder = os.path.join(output_folder, str(label))\n",
    "            os.makedirs(label_folder, exist_ok=True)\n",
    "\n",
    "            # Copy the image to the appropriate label folder\n",
    "            source_path = os.path.join(image_folder, assigned_image)\n",
    "            destination_path = os.path.join(label_folder, assigned_image)\n",
    "            shutil.copy(source_path, destination_path)\n",
    "        else:\n",
    "            print(f\"No image found for Sample_num {sample_num}\")\n",
    "\n",
    "    print(f\"Images organized into {output_folder}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jnlTtDVbBxMq"
   },
   "outputs": [],
   "source": [
    "def get_labels_from_folder(organized_folder):\n",
    "    \"\"\"\n",
    "    Extract labels and file paths from the organized folder.\n",
    "\n",
    "    Args:\n",
    "\n",
    "    organized_folder (str): Path to the folder with subfolders as class labels.\n",
    "\n",
    "        Returns:\n",
    "\n",
    "    filenames (list): List of file paths.\n",
    "    labels (list): List of corresponding class labels.\"\"\"\n",
    "    filenames = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterate through subfolders\n",
    "    for label_folder in os.listdir(organized_folder):\n",
    "        label_path = os.path.join(organized_folder, label_folder)\n",
    "        if os.path.isdir(label_path):  # Ensure it's a directory\n",
    "            for file in os.listdir(label_path):\n",
    "                if file.lower().endswith(('.tif')):\n",
    "                    filenames.append(os.path.join(label_path, file))\n",
    "                    labels.append(label_folder)  # Use string label directly\n",
    "\n",
    "    return filenames, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ANdH7egkBxMr",
    "outputId": "7e6cdfcc-f7ab-41cb-9efa-b693663f2979"
   },
   "outputs": [],
   "source": [
    "#organized_folder = \"/content/drive/MyDrive/Landcover-Classification_11-17/Organized_Images\"\n",
    "organized_folder = \"Organized_Images/\"\n",
    "\n",
    "#Get file paths and string labels\n",
    "filepaths, string_labels = get_labels_from_folder(organized_folder)\n",
    "\n",
    "#Encode string labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(string_labels)\n",
    "\n",
    "#Ensure actual_labels matches the number of samples\n",
    "print(f\"Number of files: {len(filepaths)}, Number of labels: {len(string_labels)}\")\n",
    "\n",
    "#Print mapping of string labels to integers (optional)\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(f\"Label mapping: {label_mapping}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xTrtHYIBxMr"
   },
   "source": [
    "### Label Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mG7M3bpRBxMr",
    "outputId": "a40dc40f-4061-4877-d2e8-d34dd8110810"
   },
   "outputs": [],
   "source": [
    "# Count frequency of each label\n",
    "label_counts = Counter(y)\n",
    "\n",
    "# Map back to string labels for better interpretability\n",
    "string_label_counts = {label_encoder.inverse_transform([k])[0]: v for k, v in label_counts.items()}\n",
    "\n",
    "# Prepare data for the table\n",
    "table_data = [(label, count) for label, count in string_label_counts.items()]\n",
    "headers = [\"Label\", \"Frequency\"]\n",
    "\n",
    "# Display as a table\n",
    "print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bb2jVKuaBxMr",
    "outputId": "9c3dd7d8-47d2-4a29-ca7e-9b7a57eb5bc0"
   },
   "outputs": [],
   "source": [
    "# Track labels with less than 50 occurrences\n",
    "infrequent_labels = {k: v for k, v in string_label_counts.items() if v < 50}\n",
    "\n",
    "# Prepare data for the table\n",
    "infrequent_labels = [(label, count) for label, count in infrequent_labels.items()]\n",
    "headers = [\"Label\", \"Frequency\"]\n",
    "\n",
    "# Display as a table\n",
    "if infrequent_labels:\n",
    "    print(\"\\nLabels with fewer than 50 occurrences:\")\n",
    "    print(tabulate(infrequent_labels, headers=headers, tablefmt=\"grid\"))\n",
    "else:\n",
    "    print(\"\\nNo labels with fewer than 50 occurrences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VRXo4AhnBxMs"
   },
   "outputs": [],
   "source": [
    "def remove_infrequent_labels(X, y, min_frequency=50):\n",
    "    \"\"\"\n",
    "    Remove or ignore rows from X and y with labels that occur less than min_frequency times.\n",
    "\n",
    "    Parameters:\n",
    "        X (numpy.ndarray): Input data array.\n",
    "        y (numpy.ndarray): Label array.\n",
    "        min_frequency (int): Minimum frequency for a label to be retained.\n",
    "\n",
    "    Returns:\n",
    "        X_filtered (numpy.ndarray): Filtered input data.\n",
    "        y_filtered (numpy.ndarray): Filtered labels.\n",
    "    \"\"\"\n",
    "    # Count label frequencies\n",
    "    label_counts = Counter(y)\n",
    "\n",
    "    # Identify labels with sufficient frequency\n",
    "    valid_labels = {label for label, count in label_counts.items() if count >= min_frequency}\n",
    "\n",
    "    # Filter X and y\n",
    "    indices_to_keep = [i for i, label in enumerate(y) if label in valid_labels]\n",
    "    X_filtered = X[indices_to_keep]\n",
    "    y_filtered = y[indices_to_keep]\n",
    "\n",
    "    return X_filtered, y_filtered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34vBq0rRBxMs"
   },
   "source": [
    "## Micro CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lTBVAGIrBxMs"
   },
   "outputs": [],
   "source": [
    "def confMat(model, x_test, y_test, class_names):\n",
    "    \"\"\"\n",
    "    Plots a visual confusion matrix for a given model and test data.\n",
    "\n",
    "    Args:\n",
    "\n",
    "    model: Trained model to evaluate.\n",
    "    x_test: Test features.\n",
    "    y_test: True labels for test data.\n",
    "    class_names: List of class names corresponding to numerical labels.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Predict test images\n",
    "    predict_x = model.predict(x_test)\n",
    "    # Get corresponding predicted label\n",
    "    y_pred = np.argmax(predict_x, axis=1)\n",
    "\n",
    "    # Generate confusion matrix, ensuring all class labels are included\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=np.arange(len(class_names)))\n",
    "    df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"YlGnBu\", cbar=False)\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ziXZfN6lbRoF"
   },
   "outputs": [],
   "source": [
    "def visualize_classification_results(model, X_test, y_test, label_encoder, category, num_samples=5):\n",
    "    \"\"\"\n",
    "    Visualizes correctly and incorrectly classified images for a specific category without filepaths.\n",
    "\n",
    "    Args:\n",
    "    - model: Trained model for predictions.\n",
    "    - X_test: Test image data.\n",
    "    - y_test: Ground truth labels for test data.\n",
    "    - label_encoder: Label encoder used to map labels.\n",
    "    - category: The category to analyze (string).\n",
    "    - num_samples: Number of correct and incorrect samples to display.\n",
    "\n",
    "    Returns:\n",
    "    - None (displays images with their classifications).\n",
    "    \"\"\"\n",
    "    # Get the category's numeric label\n",
    "    category_label = label_encoder.transform([category])[0]\n",
    "\n",
    "    # Predict the labels for the test data\n",
    "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "    # Find indices of correct and incorrect predictions for the category\n",
    "    correct_indices = [\n",
    "        i for i in range(len(y_test))\n",
    "        if y_test[i] == category_label and y_pred[i] == category_label\n",
    "    ]\n",
    "    incorrect_indices = [\n",
    "        i for i in range(len(y_test))\n",
    "        if y_test[i] == category_label and y_pred[i] != category_label\n",
    "    ]\n",
    "\n",
    "    # Ensure at least one incorrect image is displayed\n",
    "    if not incorrect_indices:\n",
    "        print(f\"No incorrect classifications found for category: {category}\")\n",
    "        incorrect_indices = [i for i in range(len(y_test)) if y_pred[i] != y_test[i]]\n",
    "        print(f\"Using incorrect predictions from other categories instead.\")\n",
    "        # Optionally limit to the first `num_samples` incorrect indices\n",
    "        incorrect_indices = incorrect_indices[:num_samples]\n",
    "\n",
    "    # Plot correct classifications\n",
    "    print(f\"Correctly Classified Images for Category: {category}\")\n",
    "    for idx in correct_indices[:num_samples]:\n",
    "        image = X_test[idx]\n",
    "        plt.imshow(image.mean(axis=-1), cmap=\"viridis\")  # Use mean of all channels for grayscale\n",
    "        #plt.colorbar()\n",
    "        plt.title(f\"Correct: {category}\")\n",
    "        plt.xlabel(\"Mean of PC1, PC2, PC3\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    # Plot incorrect classifications\n",
    "    print(f\"Incorrectly Classified Images for Category: {category}\")\n",
    "    for idx in incorrect_indices[:num_samples]:\n",
    "        image = X_test[idx]\n",
    "        predicted_label = label_encoder.inverse_transform([y_pred[idx]])[0]\n",
    "        plt.imshow(image.mean(axis=-1), cmap=\"viridis\")  # Use mean of all channels for grayscale\n",
    "        #plt.colorbar()\n",
    "        plt.title(f\"Incorrect: {category} -> Predicted: {predicted_label}\")\n",
    "        plt.xlabel(\"Mean of PC1, PC2, PC3\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "drpjyHkaBxMs"
   },
   "outputs": [],
   "source": [
    "def microCNN(data):\n",
    "    # Step 1: Prepare the input and labels\n",
    "    num_samples = len(data)\n",
    "    #print(num_samples)\n",
    "\n",
    "\n",
    "    # Extract the first three principal components as features\n",
    "    X = data[['PC1', 'PC2', 'PC3']].values\n",
    "    label_encoder = LabelEncoder()  # Initialize the LabelEncoder\n",
    "    y = label_encoder.fit_transform(string_labels)  # Transform string labels to integers\n",
    "\n",
    "\n",
    "\n",
    "    #print(f\"Original shape of X: {X.shape}\")\n",
    "    #print(f\"Total elements in X: {X.size}\")\n",
    "\n",
    "\n",
    "    # Determine number of valid samples\n",
    "    num_samples = X.shape[0] // 100  # Each sample needs 10x10=100 rows\n",
    "\n",
    "    # Truncate and reshape\n",
    "    num_samples = len(y)\n",
    "    X = X[:num_samples * 100]        # Truncate extra rows\n",
    "    X = X.reshape(num_samples, 10, 10, 3)  # Reshape to (num_samples, 10, 10, 3)\n",
    "\n",
    "    # Adjust labels\n",
    "    y = y[:num_samples]\n",
    "\n",
    "    #print(f\"New shape of X: {X.shape}\")  # Should be (num_samples, 10, 10, 3)\n",
    "    #print(f\"New length of y: {len(y)}\")\n",
    "\n",
    "    # Proceed with train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y[:num_samples], test_size=0.2, random_state=42, stratify=y,)\n",
    "\n",
    "    # Remove data with labels with frequency < 50\n",
    "    '''\n",
    "    X_filtered, y_filtered = remove_infrequent_labels(X, y, min_frequency=50)\n",
    "\n",
    "    # Proceed with train-test split on the filtered data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_filtered, y_filtered, test_size=0.2, random_state=42, stratify=y_filtered\n",
    "    )\n",
    "    '''\n",
    "\n",
    "    # Step 2: Define a simple CNN\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(10, 10, 3)),  # Define input shape explicitly\n",
    "        layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_samples, activation='softmax')  # Adjust the output layer for the number of classes\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    # Step 3: Train the model ###This method might take longer to run but provides a high accuracy\n",
    "    kf = KFold(n_splits=5)\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\n\")\n",
    "    # Step 4: Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "    # Step 5: Use the model to predict\n",
    "    predictions = model.predict(X_test)\n",
    "    print(f\"Predictions: {np.argmax(predictions, axis=1)[:10]}\")\n",
    "\n",
    "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "    #print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "    # Only Display Labels With Frequency > 50\n",
    "    '''\n",
    "    # Extract just the label names (from infrequent_labels)\n",
    "    infrequent_labels_set = {label for label, _ in infrequent_labels}\n",
    "\n",
    "    # Remove infrequent labels from label_encoder.classes_\n",
    "    class_names = [class_name for class_name in label_encoder.classes_ if class_name not in infrequent_labels_set]\n",
    "\n",
    "    # Print the result\n",
    "    print(f\"Class Names: {class_names}\")\n",
    "    '''\n",
    "\n",
    "    #Retrieve class names from the label encoder\n",
    "    class_names = label_encoder.classes_\n",
    "\n",
    "    confMat(model, X_test, y_test,class_names)\n",
    "\n",
    "    visualize_classification_results(\n",
    "    model=model,                 # Your trained model\n",
    "    X_test=X_test,               # Test images\n",
    "    y_test=y_test,               # Ground truth labels\n",
    "    label_encoder=label_encoder, # LabelEncoder instance\n",
    "    category=\"Natural Wooded Land\",  # Category to visualize\n",
    "    num_samples=5                # Number of images to show\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CBrYZ9cHBxMs",
    "outputId": "7caf88dd-6092-4436-dffc-e62c4474e4c0"
   },
   "outputs": [],
   "source": [
    "pca_history1 = microCNN(data_with_pcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "izSOFrA8BxMt",
    "outputId": "c6bcd262-0228-42a5-cccb-a3acb1ecdf3f"
   },
   "outputs": [],
   "source": [
    "pca_history2 = microCNN(data_with_pcs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "obrlAVHcBxMt",
    "outputId": "404a1358-7197-471e-bf37-ccda367ccc6a"
   },
   "outputs": [],
   "source": [
    "best_val_accuracy = max(pca_history1.history['val_accuracy'])\n",
    "print(f\"Best validation accuracy with principal components 1, 2, & 3: {best_val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76Z733PhBxMt",
    "outputId": "cb949dea-edb9-4d9e-cfcb-30f6e41203d0"
   },
   "outputs": [],
   "source": [
    "best_val_accuracy2 = max(pca_history2.history['val_accuracy'])\n",
    "print(f\"Best validation accuracy with principal components 2, 3, & 4: {best_val_accuracy2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMkzkLT1BxMt"
   },
   "source": [
    "### Wow! The model perfomred well with both sets of components. However it seems like components 2, 3, and 4 are performing exceptionally well. Going forward, when we want to use the result of PCA, we'll use components 2, 3, & 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdCum_nEBxMt"
   },
   "source": [
    "## MacroCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S1XC83TYBxMu"
   },
   "outputs": [],
   "source": [
    "def macroCNN(data):\n",
    "    # Step 1: Prepare the input and labels\n",
    "    num_samples = len(data)\n",
    "\n",
    "    # Extract the first three principal components as features\n",
    "    X = data[['PC1', 'PC2', 'PC3']].values\n",
    "    y = LabelEncoder().fit_transform(string_labels)  # Encode labels if they are categorical\n",
    "\n",
    "    # Determine number of valid samples\n",
    "    num_samples = X.shape[0] // 100  # Each sample needs 10x10=100 rows\n",
    "\n",
    "    # Truncate and reshape\n",
    "    num_samples = len(y)\n",
    "    X = X[:num_samples * 100]        # Truncate extra rows\n",
    "    X = X.reshape(num_samples, 10, 10, 3)  # Reshape to (num_samples, 10, 10, 3)\n",
    "\n",
    "    # Adjust labels\n",
    "    y = y[:num_samples]\n",
    "\n",
    "    # Proceed with train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y[:num_samples], test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Step 2: Define a more complex CNN\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(10, 10, 3)),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(num_samples, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Step 3: Define ModelCheckpoint to save the best model based on validation accuracy\n",
    "    checkpoint = ModelCheckpoint('best_model.keras', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "\n",
    "    # Step 4: Train the model with the ModelCheckpoint callback\n",
    "    kf = KFold(n_splits=5)\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        macro_history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, callbacks=[checkpoint])\n",
    "\n",
    "    print(\"\\n\")\n",
    "    # Step 5: Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "    # Step 6: Use the model to predict\n",
    "    predictions = model.predict(X_test)\n",
    "    print(f\"Predictions: {np.argmax(predictions, axis=1)[:10]}\")\n",
    "\n",
    "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Retrieve class names from the label encoder\n",
    "    class_names = label_encoder.classes_\n",
    "    best_model = load_model('best_model.keras')\n",
    "    confMat(best_model, X_test, y_test, class_names)\n",
    "\n",
    "    visualize_classification_results(\n",
    "    model=best_model,                 # Your trained model\n",
    "    X_test=X_test,               # Test images\n",
    "    y_test=y_test,               # Ground truth labels\n",
    "    label_encoder=label_encoder, # LabelEncoder instance\n",
    "    category=\"Natural Wooded Land\",  # Category to visualize\n",
    "    num_samples=5                # Number of images to show\n",
    "    )\n",
    "\n",
    "    return macro_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I8um34vrBxMu",
    "outputId": "0737377b-3b00-4300-e19f-078fbf54135b"
   },
   "outputs": [],
   "source": [
    "macro_history = macroCNN(data_with_pcs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7HudJSpbBxMu",
    "outputId": "549e993b-a54a-4502-8f49-b28bc1b66814"
   },
   "outputs": [],
   "source": [
    "best_val_accuracy3 = max(macro_history.history['val_accuracy'])\n",
    "print(f\"Best validation accuracy with principal components 2, 3, & 4: {best_val_accuracy3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WmFvh-RBxMu"
   },
   "source": [
    "## RGB CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gf1vOj60BxMu"
   },
   "outputs": [],
   "source": [
    "def rgb_get_all_data(sample_directory_path):\n",
    "    # Create the frequency labels\n",
    "    columns_of_frequencies = []\n",
    "    for i in range(373):  # 373 bands\n",
    "        columns_of_frequencies.append(f\"frq{i}\")\n",
    "\n",
    "    # Get an array of the sample file names\n",
    "    filenames = get_filenames(sample_directory_path)\n",
    "\n",
    "    # Process each file into a 3D array\n",
    "    list_ds = []\n",
    "    for filename in filenames:\n",
    "        ds = tiff_to_arr(join(sample_directory_path, filename))  # Original dataset shape\n",
    "\n",
    "        # Handle NaNs in the data\n",
    "        ds = np.nan_to_num(ds, nan=0)  # Replace NaNs with 0 (or use `nan=np.nanmean(ds)` for mean replacement)\n",
    "\n",
    "        # Resize if not 10x10\n",
    "        if ds.shape[1:] != (10, 10):\n",
    "            print(f\"Resizing dataset {filename} from shape {ds.shape[1:]} to (10, 10)\")\n",
    "            ds = np.array([resize(band, (10, 10), mode='constant', anti_aliasing=True) for band in ds])\n",
    "\n",
    "        list_ds.append(ds)\n",
    "\n",
    "    # Stack all datasets into a single array (num_samples, bands, 10, 10)\n",
    "    all_data = np.stack(list_ds, axis=0)  # Shape: (num_samples, bands, 10, 10)\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WbShPMC_BxMv",
    "outputId": "72c909ff-5659-4309-a2b2-8b61f9c63daa"
   },
   "outputs": [],
   "source": [
    "# Load 3D data\n",
    "all_data = rgb_get_all_data(path_samples)  # Shape: (num_samples, bands, 10, 10)\n",
    "\n",
    "# Select RGB channels by indices (frq57, frq35, frq21 correspond to indices 57, 35, 21)\n",
    "rgb_data = all_data[:, [57, 35, 21], :, :]  # Shape: (num_samples, ndim, height, width) (num_samples, 3, 10, 10)\n",
    "\n",
    "# Rearrange dimensions to match CNN input expectations (num_samples, height, width, ndim)\n",
    "rgb_data = np.transpose(rgb_data, (0, 2, 3, 1))  # Shape becomes (num_samples, 10, 10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CaJ-HKV7BxMv"
   },
   "outputs": [],
   "source": [
    "# Encode string labels into integers\n",
    "y = LabelEncoder().fit_transform(string_labels)\n",
    "\n",
    "# Ensure alignment of data and labels\n",
    "num_samples = min(rgb_data.shape[0], len(y))\n",
    "rgb_data = rgb_data[:num_samples]\n",
    "y = y[:num_samples]\n",
    "\n",
    "# Step 1: Proceed with train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(rgb_data, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vtU0gNnqBxMv",
    "outputId": "2e66c63f-44f7-4257-e3c8-ba23a16c4eff"
   },
   "outputs": [],
   "source": [
    "# Step 2: Define a simple CNN\n",
    "model1 = models.Sequential([\n",
    "    layers.Input(shape=(10, 10, 3)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(12, activation='softmax')  # 12 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model1.compile(optimizer=Adam(learning_rate=0.0005),\n",
    "               loss='sparse_categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "# Define ModelCheckpoint to save the best model based on validation accuracy\n",
    "checkpoint = ModelCheckpoint('best_model.keras', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "\n",
    "# Step 3: Train the model\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "for train_idx, val_idx in kf.split(rgb_data, y):\n",
    "    X_train, X_val = rgb_data[train_idx], rgb_data[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    history = model1.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=75, callbacks=[checkpoint])\n",
    "\n",
    "# Load the best saved model\n",
    "best_model = load_model('best_model.keras')\n",
    "\n",
    "# Step 3: Use the best model to predict\n",
    "print(\"\\n\")\n",
    "predictions = best_model.predict(X_test)\n",
    "print(f\"Predictions: {np.argmax(predictions, axis=1)[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4wt--140BxMv",
    "outputId": "5c63c0a8-8b79-49a8-b928-643388209f3c"
   },
   "outputs": [],
   "source": [
    "class_names = label_encoder.classes_\n",
    "confMat(best_model, X_test, y_test, class_names)\n",
    "loss, accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_classification_results(\n",
    "    model=best_model,                 # Your trained model\n",
    "    X_test=X_test,               # Test images\n",
    "    y_test=y_test,               # Ground truth labels\n",
    "    label_encoder=label_encoder, # LabelEncoder instance\n",
    "    category=\"Shrubs\",  # Category to visualize\n",
    "    num_samples=5                # Number of images to show\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UgOFfXtZBxMv"
   },
   "source": [
    "# FineCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PprIheJcBxMw"
   },
   "outputs": [],
   "source": [
    "def hyperspectral_cnn(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Create a 2D CNN model for hyperspectral image classifacation with reduced overfitting.\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        # First Convolutional Block\n",
    "        layers.Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=input_shape, kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(16, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        # Second Convolutional Block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "         # Third Convolutional Block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        # Fourth Convolutional Block\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.5),\n",
    "\n",
    "        # Dense Layer\n",
    "        layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "\n",
    "        # Output Layer\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZMy_gxFaBxMw"
   },
   "outputs": [],
   "source": [
    "def get_images_and_labels_tifffile(image_folder, labels_file):\n",
    "    \"\"\"\n",
    "    Reads TIFF images and their corresponding labels from a folder and CSV file.\n",
    "    Skips images without corresponding labels in the CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    - image_folder: str, path to the folder containing the images.\n",
    "    - labels_file: str, path to the CSV file containing the labels.\n",
    "\n",
    "    Returns:\n",
    "    - X: List of image data as NumPy arrays.\n",
    "    - y: List of corresponding labels.\n",
    "    \"\"\"\n",
    "    # Read the labels CSV\n",
    "    labels_df = pd.read_csv(labels_file)\n",
    "\n",
    "    # Create a dictionary mapping Sample_num to Class\n",
    "    labels_dict = dict(zip(labels_df['Sample_num'].astype(str), labels_df['Class']))\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Get all TIFF image files\n",
    "    image_files = [f for f in os.listdir(image_folder) if f.endswith('.tif')]\n",
    "\n",
    "    for image_file in image_files:\n",
    "        # Extract the sample number from the filename\n",
    "        sample_num = image_file.split('_')[0]\n",
    "\n",
    "        # Skip images without labels\n",
    "        if sample_num not in labels_dict:\n",
    "            print(f\"No label found for image: {image_file}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "\n",
    "        try:\n",
    "            # Read the TIFF image using tifffile\n",
    "            image = imread(image_path)\n",
    "\n",
    "            # Normalize image values to [0, 1]\n",
    "            image = image.astype(np.float32) / 255.0\n",
    "\n",
    "            # Append the image and its label to the lists\n",
    "            X.append(image)\n",
    "            y.append(labels_dict[sample_num])\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {image_file}: {e}\")\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MG5_awpPBxMx"
   },
   "outputs": [],
   "source": [
    "def process_labels_and_save(csv_file_path, labels_to_remove):\n",
    "    \"\"\"\n",
    "    Processes the class labels in a CSV file:\n",
    "    - Converts all class labels to lowercase for consistency.\n",
    "    - Removes rows with specific labels and rows with NaN values.\n",
    "    - Saves a new CSV file in the same directory as the original file.\n",
    "\n",
    "    Parameters:\n",
    "    - csv_file_path: str, path to the CSV file.\n",
    "    - labels_to_remove: list, class labels to remove (not case-sensitive).\n",
    "\n",
    "    Returns:\n",
    "    - processed_df: pandas DataFrame with updated labels.\n",
    "    - new_file_path: str, path to the saved new CSV file.\n",
    "    \"\"\"\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Ensure the 'Class' column exists\n",
    "    if 'Class' not in df.columns:\n",
    "        raise ValueError(\"The CSV file must have a 'Class' column.\")\n",
    "\n",
    "    # Convert all class labels to lowercase\n",
    "    df['Class'] = df['Class'].str.lower()\n",
    "\n",
    "    # Remove rows with NaN values in the 'Class' column\n",
    "    df = df.dropna(subset=['Class'])\n",
    "\n",
    "    # Remove rows with labels to remove (case-insensitive)\n",
    "    labels_to_remove_lower = [label.lower() for label in labels_to_remove]\n",
    "    df = df[~df['Class'].isin(labels_to_remove_lower)]\n",
    "\n",
    "    # Save the processed DataFrame to a new CSV file in the same directory\n",
    "    base_dir = os.path.dirname(csv_file_path)\n",
    "    new_file_name = \"Processed_\" + os.path.basename(csv_file_path)\n",
    "    new_file_path = os.path.join(base_dir, new_file_name)\n",
    "    df.to_csv(new_file_path, index=False)\n",
    "\n",
    "    return df, new_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sw_LvvipBxMx"
   },
   "outputs": [],
   "source": [
    "\n",
    "def augment_images(X, y):\n",
    "    \"\"\"\n",
    "    Augments images stored as NumPy arrays and updates labels accordingly.\n",
    "\n",
    "    Parameters:\n",
    "    - X: List of original images as NumPy arrays.\n",
    "    - y: List of original labels.\n",
    "\n",
    "    Returns:\n",
    "    - X_augmented: List of original and augmented images as NumPy arrays.\n",
    "    - y_augmented: List of labels corresponding to X_augmented.\n",
    "    \"\"\"\n",
    "    X_augmented = X.copy()\n",
    "    y_augmented = y.copy()\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        image = X[i]\n",
    "        label = y[i]\n",
    "\n",
    "        # Flip vertically\n",
    "        flipped_vert = np.flipud(image)\n",
    "        X_augmented.append(flipped_vert)\n",
    "        y_augmented.append(label)\n",
    "\n",
    "        # Flip horizontally\n",
    "        flipped_horiz = np.fliplr(image)\n",
    "        X_augmented.append(flipped_horiz)\n",
    "        y_augmented.append(label)\n",
    "\n",
    "        # Rotate 90 degrees clockwise\n",
    "        rotated = np.rot90(image, k=-1)\n",
    "        X_augmented.append(rotated)\n",
    "        y_augmented.append(label)\n",
    "\n",
    "        rotated_counterclockwise = np.rot90(image, k=1)\n",
    "        X_augmented.append(rotated_counterclockwise)\n",
    "        y_augmented.append(label)\n",
    "\n",
    "    return X_augmented, y_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def augment_hyperspectral(X, y):\n",
    "    \"\"\"\n",
    "    Applies hyperspectral-specific augmentations (band dropping and spectral shift) to images.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: List/array of images with shape (N, 10, 10, 373)\n",
    "    - y: List/array of corresponding labels\n",
    "    \n",
    "    Returns:\n",
    "    - X_augmented: List containing original and augmented images\n",
    "    - y_augmented: List containing corresponding labels\n",
    "    \"\"\"\n",
    "    X_augmented = list(X)\n",
    "    y_augmented = list(y)\n",
    "    \n",
    "    def band_selection(img, drop_ratio=0.1):\n",
    "        \"\"\"\n",
    "        Randomly drops a percentage of bands\n",
    "        \n",
    "        Parameters:\n",
    "        - img: Input image\n",
    "        - drop_ratio: Percentage of bands to drop (default: 0.1)\n",
    "        \n",
    "        Returns:\n",
    "        - Modified image with selected bands set to 0\n",
    "        \"\"\"\n",
    "        bands_to_drop = random.sample(range(img.shape[-1]), \n",
    "                                    int(img.shape[-1] * drop_ratio))\n",
    "        img_new = img.copy()\n",
    "        img_new[..., bands_to_drop] = 0\n",
    "        return img_new\n",
    "    \n",
    "    def spectral_shift(img, max_shift=5):\n",
    "        \"\"\"\n",
    "        Shifts the spectral bands by a random amount\n",
    "    \n",
    "        Parameters:\n",
    "        - img: Input image\n",
    "        - max_shift: Maximum number of bands to shift (default: 5)\n",
    "    \n",
    "        Returns:\n",
    "        - Modified image with shifted bands\n",
    "        \"\"\"\n",
    "        shift = random.randint(-max_shift, max_shift)\n",
    "        img_new = np.zeros_like(img)\n",
    "    \n",
    "        if shift == 0:\n",
    "            return img.copy()\n",
    "    \n",
    "        if shift > 0:\n",
    "            img_new[..., shift:] = img[..., :-shift]\n",
    "            img_new[..., :shift] = img[..., -shift:]  # Changed this line\n",
    "        else:\n",
    "            shift = abs(shift)  # Convert negative shift to positive for indexing\n",
    "            img_new[..., :-shift] = img[..., shift:]\n",
    "            img_new[..., -shift:] = img[..., :shift]\n",
    "    \n",
    "        return img_new\n",
    "    \n",
    "    # Apply augmentations to each image\n",
    "    for i in range(len(X)):\n",
    "        image = X[i]\n",
    "        label = y[i]\n",
    "        \n",
    "        if label == \"shrubs\":\n",
    "            # Skip augmentation for shrubs\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        # Apply band dropping\n",
    "        augmented = band_selection(image)\n",
    "        X_augmented.append(augmented)\n",
    "        y_augmented.append(label)\n",
    "        \n",
    "        # Apply spectral shifting\n",
    "        augmented = spectral_shift(image)\n",
    "        X_augmented.append(augmented)\n",
    "        y_augmented.append(label)\n",
    "        \n",
    "        if label == \"waterbodies\":\n",
    "            # Skip augmentation for waterbodies\n",
    "            continue\n",
    "        \n",
    "        if label == \"annual crops\":\n",
    "            # Skip augmentation for annual crops\n",
    "            continue\n",
    "        \n",
    "        if label == \"natural wooded land\":\n",
    "            # Skip augmentation for natural wooded land\n",
    "            continue\n",
    "        \n",
    "        # Apply both augmentations together\n",
    "        augmented = spectral_shift(band_selection(image))\n",
    "        X_augmented.append(augmented)\n",
    "        y_augmented.append(label)\n",
    "    \n",
    "    return np.array(X_augmented), np.array(y_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zzSdd9UIBxMx"
   },
   "outputs": [],
   "source": [
    "def prepare_data_for_training(X, y, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Prepares data for training by resizing and normalizing images and splitting into train/test sets.\n",
    "\n",
    "    Parameters:\n",
    "    - X: List of images as NumPy arrays.\n",
    "    - y: List of labels.\n",
    "    - test_size: Fraction of the dataset to reserve for testing.\n",
    "    - random_state: Seed for random number generator.\n",
    "\n",
    "    Returns:\n",
    "    - X_train: Training images as NumPy arrays.\n",
    "    - X_test: Testing images as NumPy arrays.\n",
    "    - y_train: Training labels.\n",
    "    - y_test: Testing labels.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Define target image size\n",
    "    target_size = (10,10)\n",
    "\n",
    "    # Initialize lists to hold resized image arrays\n",
    "    X_resized = []\n",
    "\n",
    "    for img in X:\n",
    "        # Resize image using OpenCV\n",
    "        resized_img = cv2.resize(img, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "        X_resized.append(resized_img)\n",
    "\n",
    "    # Normalize pixel values to [0, 1]\n",
    "    X_resized = np.array(X_resized).astype(np.float32) / 255.0\n",
    "    y_array = np.array(y)\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_resized, y_array,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        stratify=y_array\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gRMu7CjHBxMx"
   },
   "outputs": [],
   "source": [
    "def clean_data(X, y, target_shape=(10, 10)):\n",
    "    \"\"\"\n",
    "    Cleans and preprocesses the data:\n",
    "    - Removes invalid samples (nan or inf values in X).\n",
    "    - Resizes images to the target shape.\n",
    "\n",
    "    Parameters:\n",
    "    - X: list of image data (e.g., NumPy arrays of varying shapes).\n",
    "    - y: list of corresponding labels.\n",
    "    - target_shape: tuple, desired (height, width) for resizing images.\n",
    "\n",
    "    Returns:\n",
    "    - X_cleaned: numpy.ndarray, cleaned and resized input data.\n",
    "    - y_cleaned: numpy.ndarray, cleaned labels.\n",
    "    \"\"\"\n",
    "    X_cleaned = []\n",
    "    y_cleaned = []\n",
    "\n",
    "    for i, img in enumerate(X):\n",
    "        # Check for valid images (no nan or inf values)\n",
    "        if img is not None and not np.isnan(img).any() and not np.isinf(img).any():\n",
    "            try:\n",
    "                # Resize image to target shape while preserving channels\n",
    "                current_shape = img.shape\n",
    "                if current_shape[:2] != target_shape:\n",
    "                    zoom_factors = (target_shape[0] / current_shape[0],\n",
    "                                    target_shape[1] / current_shape[1],\n",
    "                                    1)  # Keep channels unchanged\n",
    "                    img = zoom(img, zoom_factors, order=1)  # Bilinear interpolation\n",
    "\n",
    "                # Append the resized and valid image\n",
    "                X_cleaned.append(img)\n",
    "                y_cleaned.append(y[i])\n",
    "            except AttributeError:\n",
    "                print(f\"Image {i} is not a valid NumPy array. Skipping.\")\n",
    "        else:\n",
    "            print(f\"Image {i} contains invalid values (nan or inf). Skipping.\")\n",
    "\n",
    "    return X_cleaned, y_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S3Z0GLmlBxMx"
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_training_history(history, cnn_model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Plots the training and validation accuracy and loss from the history object.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    y_pred = cnn_model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "    # Display the confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=range(len(np.unique(y_test))))\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LYEzdwnIBxMy"
   },
   "outputs": [],
   "source": [
    "def plot_class_distribution(y, class_names, title=\"Class Distribution\"):\n",
    "    \"\"\"\n",
    "    Plots a histogram showing the distribution of samples across classes.\n",
    "\n",
    "    Parameters:\n",
    "    - y: array-like, labels for the dataset (as strings or integers).\n",
    "    - class_names: list, names of the classes corresponding to the labels.\n",
    "    - title: str, title for the plot.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Count occurrences of each class\n",
    "    class_counts = Counter(y)\n",
    "    \n",
    "    # Ensure the order of bars matches class_names\n",
    "    counts = [class_counts.get(cls, 0) for cls in class_names]\n",
    "\n",
    "    # Create a bar plot\n",
    "    plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
    "    plt.bar(class_names, counts)\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "    plt.grid(axis='y')\n",
    "    plt.tight_layout()  # Adjust layout to prevent label cutoff\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7A1KyL4LBxMy"
   },
   "outputs": [],
   "source": [
    "def get_class_counts(y, class_names=None):\n",
    "    \"\"\"\n",
    "    Returns the count of samples for each class in the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - y: array-like, labels for the dataset (as strings or integers).\n",
    "    - class_names: list, optional, names of the classes corresponding to the labels.\n",
    "\n",
    "    Returns:\n",
    "    - class_counts: dict, mapping of class names (or labels) to their counts.\n",
    "    \"\"\"\n",
    "    # Count occurrences of each class\n",
    "    class_counts = Counter(y)\n",
    "\n",
    "    # Map counts to class names if provided\n",
    "    if class_names is not None:\n",
    "        class_counts = {class_names[int(label)]: count for label, count in class_counts.items()}\n",
    "\n",
    "    return class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kz-Ws4QuBxMy"
   },
   "outputs": [],
   "source": [
    "\"\"\"Add class weights to help with data imbalance\"\"\"\n",
    "def calculate_class_weights(class_counts):\n",
    "    \"\"\"\n",
    "    Calculates class weights to handle class imbalance.\n",
    "\n",
    "    Parameters:\n",
    "    - class_counts: dict, mapping of class names or indices to their counts.\n",
    "\n",
    "    Returns:\n",
    "    - class_weights: dict, mapping of class indices to weights.\n",
    "    \"\"\"\n",
    "    total_samples = sum(class_counts.values())\n",
    "    num_classes = len(class_counts)\n",
    "\n",
    "    # Ensure class indices are numeric\n",
    "    class_weights = {\n",
    "        idx: total_samples / (num_classes * count)\n",
    "        for idx, count in enumerate(class_counts.values())\n",
    "    }\n",
    "\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_predictions(model, X_test, y_test, num_images=10):\n",
    "    # Ensure the model and data are compatible\n",
    "    assert len(X_test) == len(y_test), \"X_test and y_test must have the same length.\"\n",
    "\n",
    "    # Randomly select indices\n",
    "    indices = random.sample(range(len(X_test)), min(num_images, len(X_test)))\n",
    "\n",
    "    # Predict labels\n",
    "    selected_images = np.array([X_test[i] for i in indices])\n",
    "    selected_actual_labels = [y_test[i] for i in indices]\n",
    "    predictions = model.predict(selected_images)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Display images with string labels\n",
    "    for i, index in enumerate(indices):\n",
    "        image = X_test[index]\n",
    "        actual_label = int_to_label[selected_actual_labels[i]]  # Convert back to string\n",
    "        predicted_label = int_to_label[predicted_labels[i]]     # Convert back to string\n",
    "\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.imshow(image[:, :, 0], cmap='gray' if image.shape[-1] == 1 else None)\n",
    "        plt.title(f\"Actual: {actual_label}\\nPredicted: {predicted_label}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OWNNu7aBBxMy",
    "outputId": "e270cab7-7be9-435e-c2f8-05ac23e9e1bb"
   },
   "outputs": [],
   "source": [
    "imageFolderPath = 'Data/Images'\n",
    "labelsFilePath = 'Data/ConsolidatedLabels.csv'\n",
    "\n",
    "df, new_file_path = process_labels_and_save(labelsFilePath, ['nan', 'Tie', '#N/A', 'Mixed or Not Classified', 'Wetlands', 'Planted Forest', '\"Permanent Crops (e.g., vineyard)\"'])\n",
    "\n",
    "tifffile_X, tifffile_y = get_images_and_labels_tifffile(imageFolderPath, new_file_path)\n",
    "print(f\"Original data: {len(tifffile_X)} images, {len(tifffile_y)} labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tifffile_X, cleaned_tifffile_y = clean_data(tifffile_X, tifffile_y, (10, 10))\n",
    "\n",
    "print(f\"Cleaned data: {len(cleaned_tifffile_X)} images, {len(cleaned_tifffile_y)} labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LH0tDrM1BxMy",
    "outputId": "60f311d9-074d-4324-98a3-83f824a6f99c"
   },
   "outputs": [],
   "source": [
    "new_tifffile_X, new_tifffile_y = augment_images(cleaned_tifffile_X, cleaned_tifffile_y)\n",
    "\n",
    "print(f\"Augmented data: {len(new_tifffile_X)} images, {len(new_tifffile_y)} labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_hyperspectral_X, augment_hyperspectral_y = augment_hyperspectral(new_tifffile_X, new_tifffile_y)\n",
    "print(f\"Augmented hyperspectral data: {len(augment_hyperspectral_X)} images, {len(augment_hyperspectral_y)} labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = prepare_data_for_training(augment_hyperspectral_X, augment_hyperspectral_y)\n",
    "\n",
    "\n",
    "\n",
    "cnn_model = hyperspectral_cnn(input_shape=(10, 10, 373), num_classes=len(np.unique(y_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T6GEzcLaBxMz",
    "outputId": "9794051b-3373-4e9b-8bb3-8006a981a764"
   },
   "outputs": [],
   "source": [
    "# Create bidirectional mappings\n",
    "unique_labels = sorted(set(y_train))\n",
    "label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "int_to_label = {idx: label for label, idx in label_to_int.items()}\n",
    "\n",
    "# Store original string labels before conversion\n",
    "y_train_strings = y_train.copy()  # Keeps original string labels\n",
    "y_test_strings = y_test.copy()    # Keeps original string labels\n",
    "\n",
    "# Convert to integers for training\n",
    "y_train = np.array([label_to_int[label] for label in y_train], dtype=np.int32)\n",
    "y_test = np.array([label_to_int[label] for label in y_test], dtype=np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sFYpEsFQBxMz",
    "outputId": "41ffc864-9f32-479c-e46a-9b1b28afb21a"
   },
   "outputs": [],
   "source": [
    "# Print shapes to check compatibility\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"Model input shape:\", cnn_model.input_shape)\n",
    "\n",
    "# Print data types to ensure consistency\n",
    "print(\"X_train dtype:\", X_train.dtype)\n",
    "print(\"X_test dtype:\", X_test.dtype)\n",
    "print(\"y_train dtype:\", type(y_train))\n",
    "print(\"y_test dtype:\", type(y_test))\n",
    "\n",
    "# Convert y_train and y_test to NumPy arrays with integer type\n",
    "y_train = np.array(y_train, dtype=np.int32)\n",
    "y_test = np.array(y_test, dtype=np.int32)\n",
    "\n",
    "# Verify the conversion\n",
    "print(\"y_train dtype:\", y_train.dtype)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test dtype:\", y_test.dtype)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# Convert X_train and X_test to NumPy arrays with float32 type\n",
    "X_train = np.array(X_train, dtype=np.float32)\n",
    "X_test = np.array(X_test, dtype=np.float32)\n",
    "\n",
    "# Verify the conversion\n",
    "print(\"X_train dtype:\", X_train.dtype)\n",
    "print(\"X_test dtype:\", X_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1g3MH1OBxMz",
    "outputId": "3da586d5-e23d-4551-ec7b-19e5c30df54a"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3, min_lr=1e-6)\n",
    "\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_predictions(cnn_model, X_test, y_test, len(set(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xcdmWKv-BxMz",
    "outputId": "406287b6-9372-4fe5-a521-ce371bd3fcd6"
   },
   "outputs": [],
   "source": [
    "plot_training_history(history, cnn_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HFFJaVCPBxM0",
    "outputId": "7c787d91-39af-45af-943f-f544c631cce6"
   },
   "outputs": [],
   "source": [
    "# Get the highest validation accuracy and corresponding epoch\n",
    "best_val_accuracy = max(history.history['val_accuracy'])\n",
    "best_epoch = history.history['val_accuracy'].index(best_val_accuracy) + 1\n",
    "\n",
    "print(f\"Highest Validation Accuracy: {best_val_accuracy:.4f}\")\n",
    "print(f\"Epoch with Highest Validation Accuracy: {best_epoch}\")\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_pred = cnn_model.predict(X_test)\n",
    "\n",
    "# Convert to percentages\n",
    "y_pred_percentages = y_pred * 100\n",
    "\n",
    "for i in range(best_epoch):\n",
    "    print(f\"Sample {i}:\")\n",
    "    for cls, prob in enumerate(y_pred_percentages[i]):\n",
    "        print(f\"  Class {cls}: {prob:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "koC4vI1aBxM0",
    "outputId": "f093491f-edb9-4e7b-f372-b61f0105ae2d"
   },
   "outputs": [],
   "source": [
    "# Assuming y_train and y_test are NumPy arrays or lists of numeric or string labels\n",
    "combined_labels = np.concatenate((y_train, y_test))  # Combine datasets if needed\n",
    "combined_labels = [str(label) for label in combined_labels]  # Convert to strings if necessary\n",
    "\n",
    "# Define class names (if numeric labels are used)\n",
    "class_names = sorted(set(combined_labels))  # Replace with your actual class names if needed\n",
    "\n",
    "# Get class counts\n",
    "class_counts = get_class_counts(combined_labels)\n",
    "\n",
    "# Print class counts\n",
    "for class_name, count in class_counts.items():\n",
    "    print(f\"{class_name}: {count}\")\n",
    "\n",
    "# Plot the class distribution\n",
    "plot_class_distribution(combined_labels, class_names, title=\"Class Distribution for Entire Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K79u7_U1BxM0",
    "outputId": "8272cadd-8417-4702-c7d7-91b64420b288"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Example usage\n",
    "# Combine training and testing labels\n",
    "combined_labels = np.concatenate((y_train, y_test))  # Ensure y_train and y_test are NumPy arrays\n",
    "combined_labels = [str(label) for label in combined_labels]  # Convert labels to strings if needed\n",
    "\n",
    "# Dynamically get class counts\n",
    "class_counts = get_class_counts(combined_labels)\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = calculate_class_weights(class_counts)\n",
    "\n",
    "# Print class weights for verification\n",
    "print(\"Class Weights:\")\n",
    "for idx, (class_name, weight) in enumerate(zip(class_counts.keys(), class_weights.values())):\n",
    "    print(f\"Class {idx} ('{class_name}') weight: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WtLDo_tXBxM1",
    "outputId": "bbb4ab82-4d8b-4d8c-9afb-91eddc9f149c"
   },
   "outputs": [],
   "source": [
    "# Calculate class weights\n",
    "class_weights = calculate_class_weights(class_counts)\n",
    "\n",
    "cnn_model_2 = hyperspectral_cnn(input_shape=(10, 10, 373), num_classes=12)\n",
    "\n",
    "# Train the model with class weights\n",
    "history_2 = cnn_model_2.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stopping, lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w_o9rrCuBxM1",
    "outputId": "20375730-f652-491e-8294-dfb3ac6fda66"
   },
   "outputs": [],
   "source": [
    "# Plot accuracy vs val_accuracy\n",
    "plt.plot(history_2.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_2.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot loss vs val_loss\n",
    "plt.plot(history_2.history['loss'], label='Training Loss')\n",
    "plt.plot(history_2.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Get predicted labels\n",
    "y_pred_2 = cnn_model_2.predict(X_test)\n",
    "y_pred_classes_2 = np.argmax(y_pred_2, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix_2 = confusion_matrix(y_test, y_pred_classes_2)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix_2, display_labels=range(12))\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i9uGgwt8BxM1",
    "outputId": "714bc2de-0328-410c-e331-4df8482d9a6e"
   },
   "outputs": [],
   "source": [
    "# Get the highest validation accuracy and corresponding epoch\n",
    "best_val_accuracy_2 = max(history_2.history['val_accuracy'])\n",
    "best_epoch_2 = history_2.history['val_accuracy'].index(best_val_accuracy_2) + 1\n",
    "\n",
    "print(f\"Highest Validation Accuracy: {best_val_accuracy_2:.4f}\")\n",
    "print(f\"Epoch with Highest Validation Accuracy: {best_epoch_2}\")\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_pred_2 = cnn_model_2.predict(X_test)\n",
    "\n",
    "# Convert to percentages\n",
    "y_pred_percentages_2 = y_pred_2 * 100\n",
    "\n",
    "for i in range(best_epoch_2):\n",
    "    print(f\"Sample {i}:\")\n",
    "    for cls, prob in enumerate(y_pred_percentages_2[i]):\n",
    "        print(f\"  Class {cls}: {prob:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
